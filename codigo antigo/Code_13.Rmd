---
title: "Glioma biomarkers to distinguish high-risk from low-risk patients"
author: "Beatriz Leitão and Susana Vinga"
date: "May, 2024"
output:
  html_document: 
    number_sections: yes
    toc: yes
params:
  seed: !r 3390
  train: !r 0.7
  nfolds: !r 10
editor_options:
  chunk_output_type: inline
---
# Install packages

```{r results = 'hide', message=FALSE, warning=FALSE}
# List of required packages
required_packages <- c(
  "lsa", "SnowballC", "propagate", "minpack.lm", "ff", "bit", "Rcpp", "tmvtnorm", "gmm",
  "sandwich", "mvtnorm", "VennDiagram", "futile.logger",
  "SIS", "survMisc", "risksetROC", "MASS", "survivalROC", "caTools", "pROC",
  "writexl", "openxlsx", "caret", "lattice", "glmnet", "Matrix", "survminer", "ggpubr",
  "survival", "DT", "lubridate", "forcats", "stringr", "purrr", "readr", "tidyr", "ggplot2",
  "tidyverse", "tibble", "dplyr", "matrixStats", "grf", "Boruta", "timeROC", "qvalue"
)

# Install missing packages
installed_packages <- rownames(installed.packages())
for (pkg in required_packages) {
  if (!pkg %in% installed_packages) {
    install.packages(pkg)
  }
}

# Load packages
invisible(lapply(required_packages, require, character.only = TRUE))

# List of Bioconductor packages
bioc_packages <- c(
  "MultiAssayExperiment", "TCGAbiolinks", "SummarizedExperiment", "Biobase", 
  "GenomicRanges", "GenomeInfoDb", "IRanges", "S4Vectors", "BiocGenerics", 
  "MatrixGenerics", "matrixStats", "glmSparseNet", "MultiAssayExperiment",
  "edgeR", "limma", "biomaRt", "TCGAbiolinks", "SummarizedExperiment", 
  "Biobase", "GenomicRanges", "GenomeInfoDb", "IRanges", "S4Vectors", 
  "BiocGenerics", "MatrixGenerics"
)

# Install Bioconductor packages if not installed
if (!requireNamespace("BiocManager", quietly = TRUE)) {
  install.packages("BiocManager")
}
for (pkg in bioc_packages) {
  if (!pkg %in% installed_packages) {
    BiocManager::install(pkg)
  }
}


# Load Bioconductor packages
invisible(lapply(bioc_packages, require, character.only = TRUE))

# List of CRAN packages
cran_packages <- setdiff(required_packages, bioc_packages)

# Install missing CRAN packages
installed_packages <- rownames(installed.packages())
for (pkg in cran_packages) {
  if (!pkg %in% installed_packages) {
    install.packages(pkg)
  }
}

# Load CRAN packages
invisible(lapply(cran_packages, require, character.only = TRUE))
```
# Required libraries

```{r message = FALSE}
library(TCGAbiolinks)
library(dplyr)
library(tibble)
library(tidyverse)
library(DT)
library(SummarizedExperiment)
library(survival)
library(survminer)
library(readr)
library(glmnet)
library(caret)
library(openxlsx)
library(biomaRt)
library(writexl)
library(edgeR)
library(pROC)
library(caTools)
library(survivalROC)
library(risksetROC)
library(lattice)
library(survMisc)
library(SIS)
library(VennDiagram)
library(glmSparseNet)
library(grf)
library(Boruta)
library(timeROC)
library(qvalue)
```

# Functions definition

## Prepare survival data

```{r}
# Extract survival data of interest
createSurvivalDataFrame <- function(column_names, source_data) {
  
  data_frame <- data.frame(matrix(ncol = length(column_names), nrow = nrow(source_data@colData)))
  colnames(data_frame) <- column_names

  for (col_name in column_names) {
    # Extract the column from the source and add it to the dataframe
    data_frame[[col_name]] <- source_data@colData@listData[[col_name]]
  }

  return(data_frame)
}

# Clean and prepare survival data
cleanSurvivalData <- function(data) {
  
  # apagar as linhas que têm NA no vital status
  data <- data[complete.cases(data$vital_status), ]
  
  # apagar as linhas que têm Not reported no vital status
  data <- data[data$vital_status != "Not Reported", ]
  
  # alterar o vital_status para 1 em caso de Dead e 0 se Alive
  data <- data %>%
    mutate(vital_status = ifelse(vital_status == "Alive",0,1))
  
  # criar a coluna days, assumindo os dias até à morte em caso de Dead e os dias até ao último follow up em caso de Alive
  data <- data %>% mutate(
    days = case_when(
      data$vital_status == 1 ~ data$days_to_death,
      data$vital_status == 0 ~ data$days_to_last_follow_up
    )
  )
  
  # apagar as linhas que têm NA no days
  data <- data[complete.cases(data$days), ]
  
  # deixar apenas as linhas que têm valores positivos no days
  data <- data[data$days > 0, ]
   
  # Keep only distinct rows based on the "patient" column
  data <- distinct(data, patient, .keep_all = TRUE)
  
  return(data)
}
```

## Prepare gene expression data

```{r}
# Extrair dataframe com a expressão dos genes de interesse
createGeneExpressionDataframe <- function(genes_of_interest, expression_measure, source_data, survivalData) {
  
  
  genes_table <- as.data.frame(source_data@rowRanges@elementMetadata@listData) # Tranformar a informação sobre os genes numa dataframe
  genes_table <- genes_table[genes_table$gene_type == genes_of_interest, ] #selecionar os genes de interesse
  
  expression_data <- as.data.frame(source_data@assays@data@listData[[expression_measure]]) #dataframe com a expressão de todos os genes
  colnames(expression_data) <- source_data@colData@listData[["patient"]] # adicionar os barcodes ao dataframe
  expression_data <- expression_data[, !duplicated(names(expression_data))] #remover individuos em duplicado
  rownames(expression_data) <- source_data@rowRanges@elementMetadata@listData$gene_id # adicionar o nome dos genes ao dataframe
  expression_data <- expression_data[,colnames(expression_data) %in% survivalData$patient] # selecionar apenas os individuos dos quais temos informação sobre sobrevivência
  expression_data <- as.data.frame(t(expression_data)) #transpor a dataframe
  
  data_frame <- expression_data[, colnames(expression_data) %in% genes_table$gene_id] #seleciinar a expressão dos genes de interesse
  
  return(data_frame)
}

# Clean the gene expression dataframe
cleanGeneExpressionData <- function(expression_data) {
  
  # Check if "patient" column exists in the dataframe
  if ("patient" %in% colnames(expression_data)) {
    # If "patient" column exists, use function #1
    rownames(expression_data) <- expression_data$patient # transform patients column in rowsnames
    expression_data <- expression_data[, -1] # delete the column patients 
    expression_data <- expression_data[, colSums(expression_data) != 0] #remove genes where all expression values are 0
    expression_data <- expression_data[rowSums(expression_data) != 0, ] #remove samples where the sum of the gene expression is 0
    expression_data <- expression_data %>% rownames_to_column(var = "patient") # transform row names into a column again
  } else {
    # If "patient" column doesn't exist, use function #2
    expression_data <- expression_data[, colSums(expression_data) != 0] #remove genes where all expression values are 0
    expression_data <- expression_data[rowSums(expression_data) != 0, ] #remove samples where the sum of the gene expression is 0
    expression_data <- expression_data %>% rownames_to_column(var = "patient") # transform row names into a column
    
  }
  
  return(expression_data)
}
```

## Select the disease and normalize the data

```{r}
# selecionar apenas os dados da doença de interesse
selectDataPerDisease <- function(disease, expression_data, survivalData) {
  
  #survival data
  survivalData <- survivalData[survivalData$project_id == disease, ] # select the survival data from the patients with the disease
  survivalData <- survivalData[, c('patient', 'vital_status', 'days')] # keep only the columns of interest
  #expression data
  merged_data <- merge(survivalData, expression_data, by = "patient") # select only the patients from the gene expression dataframe with the desired disease and select only the patients whose the sum of the gene expression is not zero
  expression_data <- merged_data[, c(-2,-3)] # delete the columns added above
  
  result <- list(survival_data = survivalData, genes_expression = expression_data)
  
  return(result)
}

# EdgeR normalization
normalizationEdgeR <- function(data) { 
  
  patients_IDs <- data[, 1]
  genes_expression <- t(data[, -1])
  dge <- DGEList(counts = genes_expression)
  dge <- normLibSizes(dge, method = "TMM")
  
  # usando cpm
  #normcounts <- cpm(dge)
  
  # usando o voom
  y <- voom(dge, plot=T)
  lognormcounts <- as.data.frame(y$E)
  normcounts <- as.data.frame(2^lognormcounts)
  
  genes_expression <- t(normcounts)
  genes_expression <- as.data.frame(genes_expression)
  rownames(genes_expression) <- NULL
  genes_expression <- cbind(patient = patients_IDs, genes_expression)

  return(genes_expression)
}

# ordenar os dados por paciente
orderDataByPatient <- function(data) {
  
  data <- data[order(data$patient), ]
  rownames(data) <- NULL
  
  return(data)
}

# create a dataframe with categorized gene expression (high and low)
categorizeGeneExpressionData <- function(expression_data) {
  
  categorized_expression_data <- data.frame(patient = expression_data$patient) # Create a data frame for categorized gene expression
  genes_list <- colnames(expression_data[,-1]) #create a list of genes
  
  # Loop through each gene and categorize based on the median
  for (gene in genes_list) {
    # Calculate the median expression for the gene
    median_expression <- median(expression_data[[gene]])
    
    # Create a grouping variable for the gene based on the median
    categorized_expression_data[[gene]] <- ifelse(expression_data[[gene]] > median_expression, "high", "low")
  }
  
  return(categorized_expression_data)
}
```

## Split the data in train and test

```{r}
splitTestAndTrain <- function(expression, survival, percentage) { 
  
  merged_data <- merge(survival, expression, by = "patient")
  
  # creating a sample diving into the ratio defined 
  sample <- sample.split(merged_data$patient, SplitRatio = percentage)
  
  # creating training dataset 
  train_data  <- subset(merged_data, sample == TRUE) 
  
  # creating testing dataset 
  test_data <- subset(merged_data, sample == FALSE) 
  
  # Separate survival from expression
  survival_train <- train_data[, c(1:3)]
  survival_test <- test_data[, c(1:3)]
  expression_train <- train_data[, -c(2:3)]
  expression_test <- test_data[, -c(2:3)]
  
  result <- list(survival_train = survival_train, survival_test = survival_test,
                 expression_train = expression_train, expression_test = expression_test)
  
  return(result)
}
```

## Regularized Cox Regression functions

```{r}
#preparar os dados para a Regularized Cox Regression
prepareDataForCoxRegression <- function(data) { 
  
  rownames(data) <- data$patient
  data <- data[, -1]
  data <- data.matrix(data)
  
  return(data)
}

# Extract coefficients from the fitted model
extractCoxRegressionCoefficients <- function(cox_fit) { 

  coefficients <- data.frame(as.matrix(coef(cox_fit, s = "lambda.min")))  # Choose the lambda that minimizes cross-validated error
  colnames(coefficients)[colnames(coefficients) == 'X1'] <- "Coef_value" # Change the column name 
  coefficients <- subset(coefficients, Coef_value != 0) # select only the coefficients that are not equal to zero
  #rownames(coefficients) <- sub("\\..*", "", rownames(coefficients)) # Remove the version of the gene from its name(everything after the dot including the dot)
  coefficients$ensembl_gene_id <- rownames(coefficients)
  rownames(coefficients) <- NULL
  
  # Print min lambda
  #cat("Lambda min:", "\n", cox_fit$lambda.min)

  return(coefficients)
}

```

## Get Information about the genes whose coefficient is not zero

```{r}
# Function to get gene information
getGenesInfo <- function(coefficients) {
  
  # Remove the version of the gene from its name(everything after the dot including the dot)
  coefficients$ensembl_gene_id <- sub("\\..*", "", coefficients$ensembl_gene_id) 
  
  # Connect to the Ensembl database
  #ensembl <- useMart("ensembl", dataset = "hsapiens_gene_ensembl")
  ensembl <- useEnsembl(biomart = "ensembl", dataset = "hsapiens_gene_ensembl") #mirror = "www")
    # Get information about the genes
  gene_info <- getBM(attributes = c("ensembl_gene_id", "external_gene_name", "description"),
                     filters = "ensembl_gene_id",
                     values = coefficients$ensembl_gene_id,
                     mart = ensembl)
  
  # Merge gene coefficents and gene information
  gene_info <- merge(coefficients, gene_info, by = "ensembl_gene_id")
  gene_info <- gene_info[order(-abs(gene_info$Coef_value)), ]
  
  print(gene_info)
  
  return(gene_info)
}
```

## Cumulative case/dynamic control ROC

```{r}
# fonte: https://datascienceplus.com/time-dependent-roc-for-survival-prediction-models-in-r/
# The cumulative sensitivity considers those who have died by time t
# The dynamic specificity regards those who are still alive at time t 
# This is one gives the prediction performance for the risk (cumulative incidence) of events over the t-year period.

CumulativeCaseDynamicControlROC <- function(survival_data, survival_probabilities) {
  
  ## Define a helper function to evaluate at various t
  survivalROC_helper <- function(t) {
    survivalROC(Stime        = survival_data$days,
                status       = survival_data$vital_status,
                marker       = survival_probabilities,
                predict.time = t,
                method       = "NNE",
                span = 0.25 * nrow(survival_data)^(-0.20))
  }
  ## Evaluate every X days
  survivalROC_data <- data_frame(t = ceiling(max(survival_data$days)/6) * c(1,2,3,4,5,6)) %>%
    mutate(survivalROC = map(t, survivalROC_helper),
           ## Extract scalar AUC
           auc = map_dbl(survivalROC, magrittr::extract2, "AUC"),
           ## Put cut off dependent values in a data_frame
           df_survivalROC = map(survivalROC, function(obj) {
             as_data_frame(obj[c("cut.values","TP","FP")])
           })) %>%
    dplyr::select(-survivalROC) %>%
    unnest() %>%
    arrange(t, FP, TP)
  ## Plot
  survivalROC_data %>%
    ggplot(mapping = aes(x = FP, y = TP)) +
    geom_point() +
    geom_line() +
    geom_label(data = survivalROC_data %>% dplyr::select(t,auc) %>% unique,
               mapping = aes(label = sprintf("%.3f", auc)), x = 0.5, y = 0.5) +
    facet_wrap( ~ t) +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
          legend.key = element_blank(),
          plot.title = element_text(hjust = 0.5),
          strip.background = element_blank())
}
```

## Incident case/dynamic control ROC

```{r}
# fonte: https://datascienceplus.com/time-dependent-roc-for-survival-prediction-models-in-r/
# The incident sensitivity considers those who die at time t
# The dynamic specificity regards those who are still alive at time t 
# This one gives the prediction performance for the hazard (incidence in the risk set) of events at t-year among those who are in the risk set at t.

IncidentCaseDynamicControlROC <- function(survival_data, survival_probabilities) {
  
  ## Define a helper function to evaluate at various t
  risksetROC_helper <- function(t) {
    risksetROC(Stime        = survival_data$days,
               status       = survival_data$vital_status,
               marker       = survival_probabilities,
               predict.time = t,
               method       = "Cox",
               plot         = FALSE)
  }
  ## Evaluate every 180 days
  risksetROC_data <- data_frame(t = ceiling(max(survival_data$days)/6) * c(1,2,3,4,5,6)) %>%
    mutate(risksetROC = map(t, risksetROC_helper),
           ## Extract scalar AUC
           auc = map_dbl(risksetROC, magrittr::extract2, "AUC"),
           ## Put cut off dependent values in a data_frame
           df_risksetROC = map(risksetROC, function(obj) {
             ## marker column is too short!
             marker <- c(-Inf, obj[["marker"]], Inf)
             bind_cols(data_frame(marker = marker),
                       as_data_frame(obj[c("TP","FP")]))
           })) %>%
    dplyr::select(-risksetROC) %>%
    unnest() %>%
    arrange(t, FP, TP)
  ## Plot
  risksetROC_data %>%
    ggplot(mapping = aes(x = FP, y = TP)) +
    geom_point() +
    geom_line() +
    geom_label(data = risksetROC_data %>% dplyr::select(t,auc) %>% unique,
               mapping = aes(label = sprintf("%.3f", auc)), x = 0.5, y = 0.5) +
    facet_wrap( ~ t) +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5),
          legend.key = element_blank(),
          plot.title = element_text(hjust = 0.5),
          strip.background = element_blank())
}
```

## Find the best alpha for Regularized Cox Regression model glmnet

```{r}
find_best_alpha_for_glmnet <- function(alpha_vector, genes_expression, survival_data) {
  
  # List of seed values
  seed_values <- seq(1000, 1100, by = 50)
  
  # Initialize an empty dataframe to store results
  results_df <- data.frame(matrix(nrow = length(alpha_vector), ncol = 2))
  colnames(results_df) <- c("Alpha", "Average_C_Index")
  
  # Create an empty list to store c-index values for each alpha
  c_index_list <- vector("list", length(alpha_vector))
  
  # Iterate over each alpha value
  for (i in seq_along(alpha_vector)) {
    
    cat("alpha value: ", "\n", alpha_vector[i], "\n")
    
    # Store c-index values for each seed
    c_index_values <- numeric(length(seed_values))
    
    # Iterate over each seed value
    for (j in seq_along(seed_values)) {
      
      cat("seed value: ", "\n", seed_values[j], "\n")
      
      # Split the data in train and test
      set.seed(seed_values[j])
      splited <- splitTestAndTrain(genes_expression, survival_data, 0.7)
      
      genes_expression_train <- splited$expression_train
      survival_train <- splited$survival_train
      genes_expression_test <- splited$expression_test
      survival_test <- splited$survival_test
      
      # Define survival object
      survival_object <- Surv(time = survival_train$days, event = survival_train$vital_status)
      
      # fit the Regularized Cox Regression GLMNET
      set.seed(1012)
      fit <- cv.glmnet(prepareDataForCoxRegression(genes_expression_train),
                       survival_object,
                       family = "cox",
                       #type.measure = "C",
                       alpha = alpha_vector[i])  # alpha = 1 for LASSO, 0 for ridge
     
      # Extract coefficients from the fitted model
      CoxCoefficients <- extractCoxRegressionCoefficients(fit)
     
      if (length(CoxCoefficients$ensembl_gene_id) == 0) {
        # If no coefficients found, set c-index to NA and skip to the next iteration,
        c_index_values[j] <- NA 
        
        next
      }
      
      
      # Fit a Cox regression model using the covariates
      fit <- coxph(survival_object ~ .,
                   data = subset(genes_expression_train, select = CoxCoefficients$ensembl_gene_id), # specify coefficients
                   init = as.numeric(CoxCoefficients$Coef_value), # specify coefficient values
                   iter.max = 0) # force the software to keep those values
      
      #---------------------------- Test the coefficients (predictor) found
      # Construct a risk score based on the linear predictor on the test data
      survival_probabilities_test <- predict(fit, newdata = subset(genes_expression_test, select = CoxCoefficients$ensembl_gene_id), type = "lp")
      
      # Plot AUC based on incident/dynamic definition
      riskAUC = risksetAUC(Stime=survival_test$days,
                           status = survival_test$vital_status,
                           marker = survival_probabilities_test,
                           method = "Cox",
                           tmax = ceiling(max(survival_data$days)),
                           plot = FALSE)
      
      # Store c-index value for the current seed, explicação: https://www.youtube.com/watch?v=rRYfWAsG4RI
      c_index_values[j] <- riskAUC$Cindex 
      
    }
    
    # Store c-index values for the current alpha in the list
    c_index_list[[i]] <- c_index_values
    
    # Calculate average c-index for the current alpha
    avg_c_index <- mean(c_index_values, na.rm = TRUE)
    
    # Store results in dataframe
    results_df[i, "Alpha"] <- alpha_vector[i]
    results_df[i, "Average_C_Index"] <- avg_c_index
  }
  
  # Add c-index list to results_df
  results_df$c_index_values <- c_index_list
  
  return(results_df)
}
```


## Fit models

```{r, echo=FALSE, message=FALSE, warning=FALSE}

fit_models <- function(genes_expression_train, survival_object, best_alpha, survival_train) {

 ############# Fit the Regularized Cox Regression GLMNET with the best alpha
 set.seed(1012)
 fit_COX <- cv.glmnet(prepareDataForCoxRegression(genes_expression_train),
                  survival_object,
                  family = "cox",
                  #type.measure = "C",
                  alpha = best_alpha)  # alpha = 1 for LASSO, 0 for ridge

 # Extract coefficients from the fitted model
 GLMNET_Coefficients <- extractCoxRegressionCoefficients(fit_COX)

  ############# fit the Regularized Cox Regression SIS
  set.seed(1012)
  fit_SIS <- SIS(prepareDataForCoxRegression(genes_expression_train),
             survival_object,
             family = "cox",
             penalty='lasso', # Cox model currently not implemented with the 'SCAD' (the default), 'MCP', or 'lasso' are provided
             tune='cv',
             #type.measure='deviance', #For penalty='SCAD' and penalty='MCP', only type.measure='deviance' is available
             iter = FALSE, #Specifies whether to perform iterative SIS.
             nsis = 100,
             seed = 1000) # 10GBM <- protein coding | 1000LGG <- protein and long non
  

  # Extract coefficients from the fitted model
  SIS_Coefficients <- data.frame(Coef_value = as.data.frame(fit_SIS$coef.est)[,1],
                                ensembl_gene_id = colnames(prepareDataForCoxRegression(genes_expression_train)[, fit_SIS$ix, drop = FALSE]))
  
  ############# fit the Regularized Cox Regression (I)SIS
  set.seed(1012)
  invisible(capture.output({fit_ISIS <- SIS(prepareDataForCoxRegression(genes_expression_train),
             survival_object,
             family = "cox",
             penalty='lasso', # Cox model currently not implemented with the 'SCAD' (the default), 'MCP', or 'lasso' are provided
             tune='cv',
             #type.measure='deviance', #For penalty='SCAD' and penalty='MCP', only type.measure='deviance' is available
             iter = TRUE, #Specifies whether to perform iterative SIS.
             nsis = 25,
             seed = 100, # 10GBM <- protein coding, 100GBM <- long non|| 1000LGG <- protein and long non
             varISIS='cons') #Specifies whether to perform any of the two ISIS variants based on randomly splitting the sample into two groups

  }))
  
  # Extract coefficients from the fitted model
  ISIS_Coefficients <- data.frame(Coef_value = as.data.frame(fit_ISIS$coef.est)[,1],
                                ensembl_gene_id = colnames(prepareDataForCoxRegression(genes_expression_train)[, fit_ISIS$ix, drop = FALSE]))

  ############# Fit the Causal forest model
  # Prepare the data for the causal forest
  X <- as.matrix(genes_expression_train[, -which(names(genes_expression_train) %in% c("patient"))])
  
  # Train the causal forest
  set.seed(1012)
  causal_forest_model <- causal_survival_forest(X,
                                         survival_train$days,
                                         rep(1, length(survival_train$days)),
                                         survival_train$vital_status,
                                         horizon = 1000, #max(survival_train$days, na.rm = TRUE))
                                         target = "survival.probability")
  
  # Extract feature importance from the causal forest
  importance <- variable_importance(causal_forest_model)
  
  # Select the top features based on importance
  top_features_indices <- order(importance, decreasing = TRUE)[1:100]
  top_features <- colnames(X)[top_features_indices]
  
  # Fit a Cox regression model to avoid having predictors that are highly correlated with others
  set.seed(1012)
  fit_causal_forest_model <- cv.glmnet(prepareDataForCoxRegression(subset(genes_expression_train, select = top_features)),
                                        survival_object,
                                        family = "cox",
                                        alpha = 0.3)
  
  
  # Extract coefficients from the fitted model
  CausalForest_Coefficients <- extractCoxRegressionCoefficients(fit_causal_forest_model)#data.frame(Coef_value = as.data.frame(coef(fit_causal_forest_model))[,1],                              ensembl_gene_id = rownames(as.data.frame(coef(fit_causal_forest_model))))


  ############# Fit the Boruta model
  set.seed(1012) # For reproducibility
  boruta_output <- Boruta(survival_object ~ ., 
                          data = genes_expression_train, 
                          doTrace = 2, 
                          maxRuns = 300,
                          pValue = 0.0001)
  
  # Get the significant features
  significant_features <- getSelectedAttributes(boruta_output, 
                                                withTentative = TRUE)
  
  ## Fit a Cox regression model using the covariates
  fit_boruta_model <- coxph(survival_object ~ .,
               data = subset(genes_expression_train, select = significant_features))#, # specify coefficients
               #init = as.numeric(coefficients), # specify coefficient values
               #iter.max = 0) # force the software to keep those values
  
  # Extract coefficients from the fitted model
  Boruta_Coefficients <- data.frame(Coef_value = as.data.frame(coef(fit_boruta_model))[,1],
                                    ensembl_gene_id = rownames(as.data.frame(coef(fit_boruta_model))))
  
  
  models_coefficients <- list(GLMNET_Coefficients, SIS_Coefficients, ISIS_Coefficients,
                              CausalForest_Coefficients, Boruta_Coefficients)
  
  # Return the dataframe and the fitted models
  return(models_coefficients)
  
}
```
## Compare the fitted models

```{r}
compare_models <- function(models_coefficients, genes_expression_train, genes_expression_test,
                            survival_object, survival_test, survival_data) {

  # Initialize an empty dataframe to store results
  models_evaluation_df <- data.frame(matrix(nrow = length(models_coefficients), ncol = 4))
  colnames(models_evaluation_df) <- c("C_index", "Prop_Hazards_Test", "P_value", "N_coefficients")
  rownames(models_evaluation_df) <- c("GLMNET_Coefficients", "SIS_Coefficients", "ISIS_Coefficients", "CausalForest_Coefficients", "Boruta_Coefficients")
    
  # Create an empty list to store the values for each model
  c_index_list <- vector("list", length(models_coefficients))
  prop_hazards_list <- vector("list", length(models_coefficients))
  p_values_list <- vector("list", length(models_coefficients))
  n_coeff_list <- vector("list", length(models_coefficients))
    
    # Iterate over each model 
    for (i in seq_along(models_coefficients)) {
      print(i)
      if (length(models_coefficients[[i]]$ensembl_gene_id) == 0) {
      # If no coefficients are available for the current model, assign zeros and continue to the next model
      models_evaluation_df[i, ] <- 0
      next
    }
      
      # Fit a Cox regression model using the covariates
      fit <- coxph(survival_object ~ ., 
               data = subset(genes_expression_train, select = models_coefficients[[i]]$ensembl_gene_id), # specify coefficients 
               init = as.numeric(models_coefficients[[i]]$Coef_value), # specify coefficient values
               iter.max = 0) # force the software to keep those values
  cat("here 1")
      # Test the proportional hazards assumption for a Cox regression model fit (coxph)
      Propo_hazards <- cox.zph(fit, transform="km", terms=TRUE, singledf=FALSE, global=TRUE)
      prop_hazards_list[[i]] <- Propo_hazards$table["GLOBAL", "p"]
  cat("here 2")   
      # Construct a risk score based on the linear predictor on the test data
      survival_probabilities_test <- predict(fit, newdata = subset(genes_expression_test, 
                                                                   select = models_coefficients[[i]]$ensembl_gene_id), type ="lp")
  cat("here 6")
      riskAUC = risksetAUC(Stime=survival_test$days,
                       status = survival_test$vital_status,
                       marker = survival_probabilities_test,
                       method = "Cox",
                       tmax = ceiling(max(survival_data$days)),
                       plot = FALSE)
  cat("here 3")
      # Store c-index value for the current model
      c_index_list[[i]] <-riskAUC$Cindex
  cat("here 4")    
      # Categorize individuals of the test data based on the median
      risk_groups <- ifelse(survival_probabilities_test > median(survival_probabilities_test), "High", "Low")
   cat("here 5")   
      # Kaplan-Meier com a separação por High/ Low
      fit_surv <- survfit(Surv(survival_test$days, survival_test$vital_status) ~ risk_groups)
      survdiff_result <- survdiff(Surv(survival_test$days, survival_test$vital_status) ~ risk_groups)
      p_values_list[[i]] <- survdiff_result$pvalue
      cat("here 7")
      # Store the number of coefficients for the current model
      n_coeff_list[[i]] <-length(models_coefficients[[i]]$ensembl_gene_id)
      cat("here 8")
      # Assign values to the dataframe for models with coefficients
      models_evaluation_df[i, "C_index"] <- riskAUC$Cindex
      models_evaluation_df[i, "Prop_Hazards_Test"] <- Propo_hazards$table["GLOBAL", "p"]
      models_evaluation_df[i, "P_value"] <- survdiff_result$pvalue
      models_evaluation_df[i, "N_coefficients"] <- length(models_coefficients[[i]]$ensembl_gene_id)
      
    }
  
  # # Assign values to the dataframe
  # models_evaluation_df$C_index <- unlist(c_index_list)
  # models_evaluation_df$Prop_Hazards_Test <- unlist(prop_hazards_list)
  # models_evaluation_df$P_value <- unlist(p_values_list)
  # models_evaluation_df$N_coefficients <- unlist(n_coeff_list)

  # Identify the index of the best model
  best_model_index <- which.max(models_evaluation_df$C_index)
  
  # Return the dataframe and the fitted models
  return(models_evaluation_df)
}
```



## Calculate martingale residuals and rank product

```{r}

# Calculate martingale residuals

calculate_martingale_residuals <- function(models_coefficients, genes_expression, survival_data) {
  
  survival_object_all <- Surv(time = survival_data$days, event = survival_data$vital_status)
  residuals_list <- list()
  
  for (i in seq_along(models_coefficients)) {
    if (length(models_coefficients[[i]]$ensembl_gene_id) == 0) {
      residuals_list[[i]] <- NULL
      next
    }
    
    fit <- coxph(survival_object_all ~ ., 
                 data = subset(genes_expression, select = models_coefficients[[i]]$ensembl_gene_id), 
                 init = as.numeric(models_coefficients[[i]]$Coef_value), 
                 iter.max = 0)
    
    martingale_residuals <- residuals(fit, type = "martingale")
    residuals_list[[i]] <- abs(martingale_residuals)
  }
  
  # Remove NULL elements
  residuals_list <- residuals_list[!sapply(residuals_list, is.null)]
  
  # Transform in a matrix
  residuals_matrix <- do.call(cbind, residuals_list)
  
  return(residuals_matrix)
}

# Calculate rank product

calculate_rank_product <- function(data_matrix) {
  n_samples <- nrow(data_matrix)
  n_models <- ncol(data_matrix)
  
  ranks <- apply(data_matrix, 2, rank, ties.method = "first")
  rank_product <- apply(ranks, 1, prod)
  
  return(rank_product)
}

```
## Rank product test by A. Verissimo (obtain p-values from the rank product matrix)

```{r results = 'hide', message=FALSE, warning=FALSE}
###############################
#
# rankprodbounds
#
# Description
#
# This function computes bounds on the p-value for rank products.
#
# Usage
#
# rankprodbounds(rho,n,k,Delta = c('lower','upper','geometric'))
#
# Arguments
#
# rho     a vector of integers corresponding to the rank products for which one wishes to
#         compute the p-value.
# n       the number of molecules.
# k       the number of replicates.
# Delta   a character string indicating whether an upper bound ('upper'), lower bound
#         ('lower'), or geometric approximation ('geometric') should be computed.
#
# Value
#
# A vector of p-values, one for each rank product.
#
# Details
#
# The exact p-value is guaranteed to be in between the lower and the upper bound. The
# geometric mean of the two bounds can be used as an approximation. Each bound is a piecewise
# continuous function of the rank product. The different pieces each have an analytic form,
# the parameters of which can be computed recursively.
#
# Note
#
# This implementation closely follows the description in Heskes, Eisinga, Breitling:
# "A fast algorithm for determining bounds and accurate approximate p-values of the
# rank product statistic for replicate experiments", further referred to as HEB.
# More specifically, this R function corresponds to the recursive variant, sketched
# as pseudocode in the additional material of HEB.
#
# updated version August 2015: fixed a bug with the help of Vicenzo Lagani
rankprodbounds <- function(rho,n,k,Delta){
  
  # INPUT HANDLING
  
  if(any(rho > n^k) || any(rho < 1)) stop('rho out of bounds')
  
  if(is.numeric(Delta) == FALSE) {
    if(Delta == 'geometric') {
      temp1 <- rankprodbounds(rho,n,k,'upper')
      temp2 <- rankprodbounds(rho,n,k,'lower')
      pvalue <- sqrt(temp1*temp2)   # geometric mean of upper and lower bound
      return(pvalue)
    }
    else {
      Delta <- switch(Delta,
                      upper = 1,        # for computing upper bound
                      lower = 0)        # for computing lower bound
    }
  }
  
  
  
  
  
  
  # COMPUTE INTERVALS THAT CONTAIN THE RANK PRODUCTS
  
  logn <- log(n)
  allj <- ceiling(-(log(rho)/logn)+k)   # index specifying the interval that contains rho 
  minj <- min(allj)                     # lowest interval index
  maxj <- max(allj)                     # highest interval index
  
  
  # INITIALIZE PARAMETERS
  
  param <- matrix(list(), nrow=k+1, ncol=maxj+1)
  for(i in 1:(k+1)){
    for(j in 1:(maxj+1)){
      param[[i,j]] <- list(a=c(),b=c(),c=c(),d=c(),e=c())
    }
  }
  
  # param is a matrix of lists; each element of param is a list with values for the parameters
  # a through e, which correspond to the parameters alpha through epsilon in HEB;
  # specifially, param[[i+1,j+1]]$a corresponds to alpha_{i,j} in HEB, etc, where the offset
  # of 1 is introduced to be able to represent, for example, alpha_{0,0};
  # a, b, and c can be vectors (with possibly different lengths for different i and j),
  # d and e are scalars
  
  
  # COMPUTE PARAMETERS
  
  for(j in minj:maxj){
    param <- updateparam(param,n,k,j,Delta)
  }
  
  # call to the function updateparam which recursively computes all parameters that are needed
  # to calculate the p-value for a rank product rho that lies in the interval with index j
  
  
  # COMPUTE RANK PRODUCTS GIVEN PARAMETERS
  
  k1 <- 1+k
  G <- rep(0,length(rho))   # G is a vector of the same length as rho,
  # for each rho bounding the number of rank products 
  for(j in unique(allj)) {  # updated: thanks to Vicenzo Lagani for pointing this out
    j1 <- 1+j
    iii <- which(allj == j)         # indices of all rank products that fall in interval j:
    # bounds for these rank products can be computed with
    # the same set of parameters                                    
    thisrho <- rho[iii]
    thisparam <- param[[k1,j1]]
    thisG <- thisparam$e
    if(j != 0) {
      nrho <- length(thisrho)
      nterms <- length(thisparam$a)
      thisG <- thisG + thisparam$d*thisrho
      d1 <- matrix(thisparam$c) %*% thisrho
      d2 <- matrix(rep(log(thisrho),nterms),nrow=nterms,byrow=TRUE) -
        t(matrix(rep(logn*(k-j+thisparam$b),nrho),nrow=nrho,byrow=TRUE))
      d3 <- t(matrix(rep(thisparam$a,nrho),nrow=nrho,byrow=TRUE)) 
      thisG <- thisG + colSums(d1*(d2^d3))
    }
    # the 10 lines above implement equation (8) in HEB
    G[iii] <- thisG
  }
  
  pvalue <- G/n^k
  return(pvalue)
}

###############################
#
# updateparam
#
# Description
#
# This subroutine updates the current set of parameters to make sure that the parameters
# corresponding to k replicates and the j'th interval are included.
#
# Arguments
#
# param   a matrix of lists, where each element of param is a list with values for the
#         parameters a through e; these parameters specify the functional form of the bound;
#         a, b, and c are all vectors of unknown length, d and e are scalars.
# n       the number of molecules.
# k       the number of replicates for which we need to compute the corresponding parameters.
# j       the index of the interval for which we need to compute the corresponding parameters.
# Delta   0 for the lower bound and 1 for the upper bound.
#
# Value
#
# A possibly updated set of parameters, at least including those corresponding to (k,j).
#
# Details
# 
# This subroutine make sure that the parameters corresponding to k replicates and a rank product
# within the j'th interval are already. If they already are (because calculated before), it
# does not compute anything. Otherwise, it recursively computes all parameters
# that are needed to arrive at the parameters for (k,j).
#
# Note
#
# This implementation closely follows HEB, in particular equations (9) through (11).

updateparam <- function(param,n,k,j,Delta) {
  
  k1 <- 1+k
  j1 <- 1+j
  
  if(length(param[[k1,j1]]$e) == 0) {  # apparently empty, so needs to be calculated
    
    if(j == 0) {   # initializing G_{k0}
      
      param[[k1,j1]]$e <- n^k
      param[[k1,j1]]$d <- 0
      # the 2 lines above implement equation (11) in HEB
      
    }
    else {
      k0 <- k1-1
      j0 <- j1-1
      param <- updateparam(param,n,k-1,j-1,Delta)
      # checking that the parameters for (k-1,j-1) that are needed to compute the
      # parameters for (k,j) are indeed available; if not, they are themselves computed
      param00 = param[[k0,j0]]
      newa0 = param00$a+1
      newb0 = param00$b
      newc0 = param00$c/newa0
      param11 = param00
      # the 5 lines above predefine some parameters common to equations (9) and (10) in HEB
      
      if(k == j){ # updates for G_{kk}
        
        param11$e <- (1-Delta)*(1-param00$e)
        param11$d <- Delta*param00$d+param00$e
        param11$a <- c(1,param00$a,newa0)
        param11$b <- c(0,param00$b,newb0)
        param11$c <- c(param00$d,Delta*param00$c,newc0)
        # the 5 lines above implement equation (10) in HEB
      }
      else {  # updates for G_{kj}, j < k
        param <- updateparam(param,n,k-1,j,Delta)
        # checking that the parameters for (k-1,j) that are needed to compute the
        # parameters for (k,j) are indeed available; if not, they are themselves computed
        param01 <- param[[k0,j1]]
        
        logn <- log(n)
        lognnkj <- (k-j)*logn
        newa1 <- param01$a+1
        newa <- c(newa0,newa1)
        newb <- c(newb0,param01$b)
        newc <- c(newc0,-param01$c/newa1)
        param11$e <- n*param01$e + (Delta-1)*(param00$e-param01$e)
        lognminb <- c(-1*param00$b * logn,(1-param01$b)*logn)
        param11$d <- Delta*param00$d + (1-Delta)*param01$d/n + 
          (param00$e-param01$e)/exp(lognnkj) - 
          sum(newc*(lognminb^newa))
        param11$a <- c(1,1,param00$a,param01$a,newa)
        param11$b <- c(0,1,param00$b,param01$b,newb)
        param11$c <- c(param00$d,-param01$d,
                       Delta*param00$c,(1-Delta)*param01$c/n,newc)
        # the 15 lines above implement equation (9) in HEB
      }
      param[[k1,j1]] <- makeunique(param11)
      # although not strictly necessary, the a, b and c vectors can possibly be shortened by
      # restricting oneselves to unique combinations of a and b values
    }
  }
  return(param)
}

###############################
#
# makeunique
#
# Description
#
# This subroutine updates the parameters for a specific number of replicates and interval
# such that it contains only unique combinations of the parameters a and b.
#
# Arguments
#
# param   a single list with values for the parameters a through e; these parameters
#         specify the functional form of the bound; a, b, and c are all vectors of
#         unknown length, d and e are scalars.
# 
# Value
#
# A possibly updated and then more concise set of parameters containing only unique
# combinations of the parameters a and b.
#
# Details
#
# While updating the vectors a and b, one may end up with the exact same combinations of
# a and b. Given the functional form of the bound, the representation can then be made more
# concise by simply adding the corresponding elements of c.

makeunique <- function(param) {
  
  ab <- t(rbind(param$a,param$b))
  uniqueab <- unique(ab)
  nunique <- dim(uniqueab)[1]
  param$a <- t(uniqueab[,1])
  param$b <- t(uniqueab[,2])
  newc <- rep(0,nunique)
  for(i in 1:nunique) {
    iii <- intersect(which(ab[,1]==uniqueab[i,1]),which(ab[,2]==uniqueab[i,2]))
    newc[i] <- sum(param$c[iii])  
  }
  param$c <- newc
  
  return(param)
  
}
```


# Download data

```{r results = 'hide', message=FALSE, warning=FALSE}

query_RNA <- GDCquery(
  project = c("TCGA-GBM", "TCGA-LGG"),
  data.category = "Transcriptome Profiling",
  data.type = "Gene Expression Quantification",
  workflow.type = "STAR - Counts",
  experimental.strategy = ("RNA-Seq")
)
# Check if files exist before downloading
if (!dir.exists("GDCdata")) {
  GDCdownload(query = query_RNA)
}

TCGA_RNA <- GDCprepare(query = query_RNA)


```

# Prepare survival data

```{r}
# Extract survival data of interest
columns_to_extract <- c("patient", "project_id", "vital_status", "days_to_death", "days_to_last_follow_up")
survival_data <- createSurvivalDataFrame(columns_to_extract, TCGA_RNA)


# Clean and prepare survival data
survival_data <- cleanSurvivalData(survival_data)
```

# Assign a new classification to the data

```{r results = 'hide', message=FALSE, warning=FALSE}
# new classification -->
new_classification <- read_csv("SIMPLIFIED_CLASSIFICATION_TCGA_2016_2021.csv") #download the classification datafram
names(new_classification)[names(new_classification) == "Patient_ID"] <- "patient" # remane the Patient_ID column
new_classification <- subset(new_classification, select = -c(TCGA.histological.type, classification.2016)) # delete unnecessary columns

# Merge the dataframes to add the disease information keeping only common patients
survival_data <- merge(survival_data, new_classification, by = "patient")
survival_data <- subset(survival_data, select = -project_id)
names(survival_data)[names(survival_data) == "classification.2021"] <- "project_id"

```

# Select and prepare expression data

```{r}
# Extrair dataframe com a expressão dos genes de interesse
genes_expression <- createGeneExpressionDataframe("protein_coding", "unstranded", TCGA_RNA, survival_data)
#genes_expression <- createGeneExpressionDataframe("lncRNA", "unstranded", TCGA_RNA, survival_data)
#genes_expression <- createGeneExpressionDataframe("miRNA", "unstranded", TCGA_RNA, survival_data)       #<------------ indicar os dados 

# Clean the gene expression dataframe
genes_expression <- cleanGeneExpressionData(genes_expression)
```

# Disease selection and data normalization

```{r}

#------------ OLD CLASSIFICATION-------------------------------------------------

# selecionar apenas os dados da doença de interesse
#data <- selectDataPerDisease("TCGA-GBM", genes_expression, survival_data)
#data <- selectDataPerDisease("TCGA-LGG", genes_expression, survival_data)                                   #<------------ indicar a doença, ajustar depois os seeds no fit do ISIS e do SIS

#------------ NEW CLASSIFICATION-------------------------------------------------

#data <- selectDataPerDisease("astrocytoma", genes_expression, survival_data)
data <- selectDataPerDisease("glioblastoma", genes_expression, survival_data)
#data <- selectDataPerDisease("oligodendroglioma", genes_expression, survival_data)

genes_expression <- data$genes_expression
survival_data <- data$survival_data

# remove genes where the sum of the gene expression is 0 (necessary to repeat this step, since there is a selection of patients) 
genes_expression <- cleanGeneExpressionData(genes_expression)

# EdgeR+voom normalization
genes_expression <- normalizationEdgeR(genes_expression)

# Clean the gene expression dataframe
genes_expression <- cleanGeneExpressionData(genes_expression)

# ordenar os dados por paciente
genes_expression <- orderDataByPatient(genes_expression)
survival_data <- orderDataByPatient(survival_data)


# create a dataframe with categorized gene expression (high and low)
#genes_expression <- categorizeGeneExpressionData(genes_expression)                                        #<------------ indicar se queremos os dados categorizados
```

# Split the data in train and test and define survival object

```{r}
# Split the data in train and test
set.seed(1012)
splited <- splitTestAndTrain(genes_expression, survival_data, 0.7)

genes_expression_train <- splited$expression_train
survival_train <- splited$survival_train
genes_expression_test <- splited$expression_test
survival_test <- splited$survival_test

# Define survival object
survival_object <- Surv(time = survival_train$days, event = survival_train$vital_status)
```

# Find the best alpha for Regularized Cox Regression model glmnet

```{r results = 'hide', message=FALSE, warning=FALSE}
# indicate the alpha values to test
alpha_vector <- seq(0.1, 1, by = 0.1) # if alpha is set to zero (ridge regression), the coxph model will give the Error: protect(): protection stack overflow

# evaluate the alpha values through multiple seeds
results_df <- find_best_alpha_for_glmnet(alpha_vector, genes_expression, survival_data)

# select the best alpha
best_alpha <- results_df$Alpha[which.max(results_df$Average_C_Index)]

results_df
```

# Fit and Explore the Models

```{r, echo=FALSE, message=FALSE, warning=FALSE}

# Fit the models
models_coefficients <- fit_models(genes_expression_train, survival_object, best_alpha, survival_train)

# Compare the models
models_evaluation_df <- compare_models(models_coefficients, genes_expression_train, genes_expression_test, survival_object, survival_test, survival_data)

models_evaluation_df

# Find the index of the model with the highest c-index
best_model_index <- which.max(models_evaluation_df$C_index)
best_model_name <- rownames(models_evaluation_df)[best_model_index]
cat(paste("Best Model:", best_model_name, "\n C-index:", round(models_evaluation_df$C_index[best_model_index], 3)))

# Get the coefficients of the best model from models_coefficients
best_model_coefficients <- models_coefficients[[best_model_index]]

# Create a Venn diagram
modelos_com_genes <- list()
nomes <- c("GLMNET", "SIS", "ISIS", "Causal Forest", "Boruta")
model_list <- models_coefficients

# Temporary list to store valid names
valid_names <- character()

# Loop through each model and check if coefficients exist
for (i in seq_along(model_list)) {
  variable <- model_list[[i]]
  if (!is.null(variable$ensembl_gene_id) && length(variable$ensembl_gene_id) > 0) {
    modelos_com_genes <- c(modelos_com_genes, list(variable$ensembl_gene_id))
    valid_names <- c(valid_names, nomes[i])
  }
}

# Replace nomes with valid names
nomes <- valid_names

if (length(nomes) == 0) {
  stop("\nNo coefficients found in any of the models")
} else if (length(nomes) == 1) {
  cat("\nOnly one model has coefficients")
} else {

venn.plot <- venn.diagram(
  x = modelos_com_genes,
  category.names = nomes,
  #disable.logging = TRUE,
  filename = NULL)

grid.newpage()
grid.draw(venn.plot)

}

```

# Indentify oultiers with the rank product test

```{r message=FALSE, warning=FALSE}

# Calculate martingale residuals for each model
martingale_residuals_matrix <- calculate_martingale_residuals(models_coefficients, genes_expression, survival_data)

rank_product_results <- calculate_rank_product(martingale_residuals_matrix)

# p-values calculation

rho = rank_product_results #rank product matrix result
n <-dim(survival_data)[1] # number of samples
k <-sum(sapply(models_coefficients, function(df) nrow(df) > 0)) # number of models with coefficients different than zero

pvalues <- as.vector(rankprodbounds(rho,n,k,Delta ='geometric')) # The p-values are obtained by the following, where Delta option is the geometric mean.

# q-values calculation

qobj<-qvalue(pvalues)
qvalues<-qobj$qvalues
outliers_rank_product <- which(qvalues<0.05)

outliers_rank_product

# Remove the rows corresponding to outliers 
genes_expression_clean <- genes_expression[-outliers_rank_product, ]
survival_data_clean <- survival_data[-outliers_rank_product, ]


```



# Fit and Explore the Models Without Outliers

```{r results = 'hide', message=FALSE, warning=FALSE}

# Split the data in train and test
set.seed(1012)
splited_clean <- splitTestAndTrain(genes_expression_clean, survival_data_clean, 0.7)

genes_expression_train_clean <- splited_clean$expression_train
survival_train_clean <- splited_clean$survival_train
genes_expression_test_clean <- splited_clean$expression_test
survival_test_clean <- splited_clean$survival_test

# Define survival object
survival_object_clean <- Surv(time = survival_train_clean$days,
                              event = survival_train_clean$vital_status)

# Fit the models without the outliers
models_coefficients_clean <- fit_models(genes_expression_train_clean, survival_object_clean, best_alpha, survival_train_clean)

# Compare the models
models_evaluation_df_clean <- compare_models(models_coefficients_clean, genes_expression_train_clean, genes_expression_test_clean, survival_object_clean, survival_test_clean, survival_data_clean)

models_evaluation_df_clean

# Find the index of the model with the highest c-index
best_model_index_clean <- which.max(models_evaluation_df_clean$C_index)
best_model_name_clean <- rownames(models_evaluation_df_clean)[best_model_index_clean]
cat(paste("Best Model:", best_model_name_clean, "\n C-index:", round(models_evaluation_df_clean$C_index[best_model_index_clean], 3)))

# Get the coefficients of the best model from models_coefficients
best_model_coefficients_clean <- models_coefficients_clean[[best_model_index_clean]]


# Create a Venn diagram
modelos_com_genes <- list()
nomes <- c("GLMNET", "SIS", "ISIS", "Causal Forest", "Boruta")
model_list <- models_coefficients_clean

# Temporary list to store valid names
valid_names_clean <- character()

# Loop through each model and check if coefficients exist
for (i in seq_along(model_list)) {
  variable <- model_list[[i]]
  if (!is.null(variable$ensembl_gene_id) && length(variable$ensembl_gene_id) > 0) {
    modelos_com_genes <- c(modelos_com_genes, list(variable$ensembl_gene_id))
    valid_names_clean <- c(valid_names_clean, nomes[i])
  }
}

# Replace nomes with valid names
nomes <- valid_names_clean

if (length(nomes) == 0) {
  stop("\nNo coefficients found in any of the models")
} else if (length(nomes) == 1) {
  cat("\nOnly one model has coefficients")
} else {

venn.plot <- venn.diagram(
  x = modelos_com_genes,
  category.names = nomes,
  #disable.logging = TRUE,
  filename = NULL)

grid.newpage()
grid.draw(venn.plot)

}

```

# Analyse the best model

```{r message=FALSE, warning=FALSE}
# Function to get gene information
gene_info_result <- getGenesInfo(best_model_coefficients_clean)

# Fit a Cox regression model using the covariates
fit_clean <- coxph(survival_object_clean ~ ., 
             data = subset(genes_expression_train_clean, select = best_model_coefficients_clean$ensembl_gene_id), # specify coefficients 
             init = as.numeric(best_model_coefficients_clean$Coef_value), # specify coefficient values
             iter.max = 0) # force the software to keep those values

# Test the proportional hazards assumption for a Cox regression model fit (coxph)
Propo_hazards <- cox.zph(fit_clean, transform="km", terms=TRUE, singledf=FALSE, global=TRUE)
Propo_hazards_global_p_value <- Propo_hazards$table["GLOBAL", "p"]

# Construct a risk score based on the linear predictor on the test data
survival_probabilities_test_clean <- predict(fit_clean, newdata = subset(genes_expression_test_clean, select = best_model_coefficients_clean$ensembl_gene_id), type = "lp")

#---------------------------- AUC


# Calculate AUC at specific time points with a specified span
times <- c(1, 3, 5)
n_events <- sum(survival_test_clean$vital_status)
span <- 0.25 * n_events^(-0.20) # equal to package developers span

auc_values <- sapply(times, function(t) {
  roc_result <- survivalROC(Stime = survival_test_clean$days,
                            status = survival_test_clean$vital_status,
                            marker = survival_probabilities_test_clean,
                            predict.time = t * 365.25,
                            method = "NNE",
                            span = span)
  roc_result$AUC
})

auc_df <- data.frame(
  Time = times,
  AUC = auc_values
)
print(auc_df)


#---------------------------- Risk AUC

riskAUC = risksetAUC(Stime=survival_test_clean$days,
                       status = survival_test_clean$vital_status,
                       marker = survival_probabilities_test_clean,
                       method = "Cox",
                       tmax = ceiling(max(survival_data_clean$days)),
                       plot = TRUE)

#---------------------------- Cumulative case/dynamic control ROC, fonte: https://datascienceplus.com/time-dependent-roc-for-survival-prediction-models-in-r/
# The cumulative sensitivity considers those who have died by time t
# The dynamic specificity regards those who are still alive at time t 
# This is one gives the prediction performance for the risk (cumulative incidence) of events over the t-year period.
CumulativeCaseDynamicControlROC(survival_test_clean, survival_probabilities_test_clean)

#---------------------------- Incident case/dynamic control ROC, fonte: https://datascienceplus.com/time-dependent-roc-for-survival-prediction-models-in-r/
# The incident sensitivity considers those who die at time t
# The dynamic specificity regards those who are still alive at time t 
# This one gives the prediction performance for the hazard (incidence in the risk set) of events at t-year among those who are in the risk set at t.
IncidentCaseDynamicControlROC(survival_test_clean, survival_probabilities_test_clean)


# Construct a risk score based on the linear predictor on the train data
survival_probabilities_train_clean <- predict(fit_clean, newdata = subset(genes_expression_train_clean, select = best_model_coefficients_clean$ensembl_gene_id), type = "lp")

# Categorize individuals of the test data based on the median
risk_groups <- ifelse(survival_probabilities_test_clean > median(survival_probabilities_test_clean), "High", "Low")

# Kaplan-Meier com a separação por High/ Low
fit_surv <- survfit(Surv(survival_test_clean$days, survival_test_clean$vital_status) ~ risk_groups)
survdiff(Surv(survival_test_clean$days, survival_test_clean$vital_status) ~ risk_groups)
ggsurvplot(fit_surv, data = survival_test_clean)
```

# See the balance of censored data in test and training

```{r}

counts_test <- table(survival_test_clean$vital_status)

# Calculate the percentage of zeros and ones
test_percent_zeros <- (counts_test[1] / sum(counts_test)) * 100
test_percent_ones <- (counts_test[2] / sum(counts_test)) * 100

counts_train <- table(survival_train_clean$vital_status)

# Calculate the percentage of zeros and ones
train_percent_zeros <- (counts_train[1] / sum(counts_train)) * 100
train_percent_ones <- (counts_train[2] / sum(counts_train)) * 100

# Create a dataframe to store the comparison
comparison <- data.frame(
  Dataframe = c("survival_test", "survival_train"),
  Alive = c(test_percent_zeros, train_percent_zeros),
  Dead = c(test_percent_ones, train_percent_ones)
)

comparison

```

# Test the best model on the train data

```{r}
# Construct a risk score based on the linear predictor on the train data
a_survival_probabilities_train <- predict(fit_clean, newdata = subset(genes_expression_train_clean, select = best_model_coefficients_clean$ensembl_gene_id), type = "lp")

# Categorize individuals of the test data based on the median
risk_groups <- ifelse(a_survival_probabilities_train > median(a_survival_probabilities_train), "High", "Low")

# Kaplan-Meier com a separação por High/ Low
fit_surv <- survfit(Surv(survival_train_clean$days, survival_train_clean$vital_status) ~ risk_groups)
survdiff(Surv(survival_train_clean$days, survival_train_clean$vital_status) ~ risk_groups)
ggsurvplot(fit_surv, data = survival_train_clean)

```
