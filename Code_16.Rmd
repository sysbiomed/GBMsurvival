---
title: "Glioma biomarkers to distinguish high-risk from low-risk patients"
author: "Beatriz N. Leitão, André Veríssimo, Alexandra M. Carvalho and Susana Vinga"
date: "November, 2024"
output:
  html_document: 
    number_sections: yes
    toc: yes
editor_options:
  chunk_output_type: inline
---

```{r init, include=FALSE}

# Trick to store functions in search path, but not enviromnent
local({
  env <- new.env()
  env$fun_source <- function(file_name) {
    env_name <- sprintf("my_functions:%s", gsub(" ", "_", basename(file_name)))
    if (env_name %in% search()) {
      detach(env_name, character.only = TRUE, unload = TRUE)
    }
    sys.source(file_name, envir = attach(NULL, name = env_name))
  }
  lapply(search()[search() %in% "fun_source"], detach, character.only = TRUE, unload = TRUE)
  attach(env, name = "fun_source")
})

# Run garbage colector after each chunk
knitr::knit_hooks$set(
  after_chunk = function(options) {
    invisible(gc())
  }
)
```

# Install packages

```{r Install_packages, results = 'hide', message=FALSE, warning=FALSE}
#renv::restore()
```

# Load libraries

```{r Load_libraries, results=FALSE, message=FALSE, warning=FALSE}
# library(TCGAbiolinks)
library(dplyr)
library(tibble)
# library(tidyverse)
library(DT)
library(SummarizedExperiment)
library(survival)
library(survminer)
# library(readr)
library(glmnet)
library(caret)
library(openxlsx)
library(biomaRt)
library(writexl)
library(edgeR)
library(pROC)
library(caTools)
library(survivalROC)
library(risksetROC)
library(lattice)
library(survMisc)
library(SIS)
library(VennDiagram)
# library(glmSparseNet)
library(randomForestSRC)
library(grf)
library(Boruta)
library(timeROC)
library(qvalue)
library(clusterProfiler)
library(org.Hs.eg.db)
library(enrichplot)
library(pathview)
library(UpSetR)
library(rsample)
library(pec)
```

# Prepare the environment, report chunk status and sessioninfo

```{r Prepare_the_environment_report_chunk_status_and_sessioninfo}

# clean current environment
rm(list = ls())

# Capture the sessionInfo() output and write it to a file
writeLines(capture.output(sessionInfo()), con = "sessioninfo.txt")

fun_source("Functions/Logger.R")

# write on the chunk end time file
log_chunk_end_time("Prepare the environment, report chunk status and sessioninfo", log_file = "chunk_times_log.txt")
```

# Download functions

```{r Download_functions}
# download the functions
fun_source("Functions/Data_preparation.R")
fun_source("Functions/Model_evaluation.R")
fun_source("Functions/Model_fitting.R")
fun_source("Functions/Rank_product_test.R")

# write on the chunk end time file
log_chunk_end_time("Download functions", log_file = "chunk_times_log.txt")
```

# Folder to store results

```{r Folder_to_store_results}

# Ensure the 'Results' directory exists
if (!dir.exists("Results")) {
  dir.create("Results")
}

# write on the chunk end time file
log_chunk_end_time("Folder to store results", log_file = "chunk_times_log.txt")
```

# Download data

```{r Download_data, results = 'hide', message=FALSE, warning=FALSE}
# Cache to use in memoise
cd <- cachem::cache_disk(here::here(".", "memoise-cache"), max_size = 3 * 1024^3)

download_data <- memoise::memoise(
  function() {
    query_RNA <- TCGAbiolinks::GDCquery(
      project = c("TCGA-GBM", "TCGA-LGG"),
      data.category = "Transcriptome Profiling",
      data.type = "Gene Expression Quantification",
      workflow.type = "STAR - Counts",
      experimental.strategy = ("RNA-Seq")
    )
    # Check if files exist before downloading
    if (!dir.exists("GDCdata")) {
      TCGAbiolinks::GDCdownload(query = query_RNA)
    }
    
    TCGAbiolinks::GDCprepare(query = query_RNA)  
  },
  cache = cd
)

TCGA_RNA <- download_data()

# write on the chunk end time file
log_chunk_end_time("Download data", log_file = "chunk_times_log.txt")
```

# Prepare survival data

```{r Prepare_survival_data}
# Extract survival data of interest
columns_to_extract <- c("patient", "project_id", "vital_status", "days_to_death", "days_to_last_follow_up")
survival_data <- createSurvivalDataFrame(columns_to_extract, TCGA_RNA)


# Clean and prepare survival data
survival_data <- cleanSurvivalData(survival_data)

# write on the chunk end time file
log_chunk_end_time("Prepare survival data", log_file = "chunk_times_log.txt")
```

# Assign a new classification to the data

```{r Assign_new_classification_to_the_data, results = 'hide', message=FALSE, warning=FALSE}
# new classification -->
new_classification <- readr::read_csv("SIMPLIFIED_CLASSIFICATION_TCGA_2016_2021.csv") #download the classification datafram
names(new_classification)[names(new_classification) == "Patient_ID"] <- "patient" # remane the Patient_ID column
new_classification <- subset(new_classification, select = -c(TCGA.histological.type, classification.2016)) # delete unnecessary columns

# Merge the dataframes to add the disease information keeping only common patients
survival_data <- merge(survival_data, new_classification, by = "patient")
survival_data <- subset(survival_data, select = -project_id) # remove old classification
names(survival_data)[names(survival_data) == "classification.2021"] <- "project_id" # aplly the old name to the new classification


# write on the chunk end time file
log_chunk_end_time("Assign a new classification to the data", log_file = "chunk_times_log.txt")
```

# Select and prepare expression data

```{r Select_and_prepare_expression_data}
# Extrair dataframe com a expressão dos genes de interesse
genes_expression <- createGeneExpressionDataframe("protein_coding", "unstranded", TCGA_RNA, survival_data)
#genes_expression <- createGeneExpressionDataframe("lncRNA", "unstranded", TCGA_RNA, survival_data)
#genes_expression <- createGeneExpressionDataframe("miRNA", "unstranded", TCGA_RNA, survival_data)       #<------------ indicar os dados 

# Clean the gene expression dataframe
genes_expression <- cleanGeneExpressionData(genes_expression)

# write on the chunk end time file
log_chunk_end_time("Select and prepare expression data", log_file = "chunk_times_log.txt")
```

```{r clean_up_tgca_rna, include=FALSE}
rm(TCGA_RNA)
log_chunk_end_time("Clean-up TGCGA RNA", log_file = "chunk_times_log.txt")
```


# Disease selection and data normalization

```{r Disease_selection_and_data_normalization}

#------------ OLD CLASSIFICATION-------------------------------------------------

# selecionar apenas os dados da doença de interesse
#data <- selectDataPerDisease("TCGA-GBM", genes_expression, survival_data)
#data <- selectDataPerDisease("TCGA-LGG", genes_expression, survival_data)                                   

#------------ NEW CLASSIFICATION-------------------------------------------------

#data <- selectDataPerDisease("astrocytoma", genes_expression, survival_data)
data <- selectDataPerDisease("glioblastoma", genes_expression, survival_data)
#data <- selectDataPerDisease("oligodendroglioma", genes_expression, survival_data)

genes_expression <- data$genes_expression
survival_data <- data$survival_data

# remove genes where the sum of the gene expression is 0 (necessary to repeat this step, since there is a selection of patients) 
genes_expression <- cleanGeneExpressionData(genes_expression)

# EdgeR+voom normalization
genes_expression <- normalizationEdgeR(genes_expression)

# Clean the gene expression dataframe
genes_expression <- cleanGeneExpressionData(genes_expression)

# ordenar os dados por paciente
genes_expression <- orderDataByPatient(genes_expression)
survival_data <- orderDataByPatient(survival_data)

# write on the chunk end time file
log_chunk_end_time("Disease selection and data normalization", log_file = "chunk_times_log.txt")
```

<!-- # Find the best alpha for Regularized Cox Regression model glmnet -->

<!-- ```{r Find_the_best_alpha_for_Regularized_Cox_Regression, message=FALSE, warning=FALSE} -->

<!-- # indicate the alpha values to test -->
<!-- #alpha_vector <- c(0.1) -->
<!-- alpha_vector <- seq(0, 0.5, by = 0.1) # if alpha is set to zero (ridge regression), the coxph model will give the Error: protect(): protection stack overflow -->

<!-- # List of seed values -->
<!-- #seed_values_alpha <- c(1) -->
<!-- seed_values_alpha <- seq(1, 10, by = 1) -->

<!-- # evaluate the alpha values through multiple seeds -->
<!-- results_df <- find_best_alpha_for_glmnet(alpha_vector, seed_values_alpha, genes_expression, survival_data) -->

<!-- # select the best alpha -->
<!-- best_alpha <- results_df$Alpha[which.max(results_df$Average_C_Index)] -->

<!-- results_df -->
<!-- cat("Best alpha: ", "\n", best_alpha, "\n") -->


<!-- # Save as CSV -->
<!-- list_columns <- sapply(results_df, is.list) # Identify list columns -->
<!-- results_df[list_columns] <- lapply(results_df[list_columns], as.character) # Convert list columns to character -->
<!-- write.csv(results_df, file = "Results/results_df.csv", row.names = FALSE) -->

<!-- # write on the chunk end time file -->
<!-- log_chunk_end_time("Find the best alpha for Regularized Cox Regression model glmnet", log_file = "chunk_times_log.txt") -->
<!-- ``` -->

# Fit and Explore the Models (train != test)

```{r Fit_and_Explore_the_Models_different, message=FALSE, warning=FALSE}

# Models' names
models_names_list <- c("Cox", "RandomForest+Cox", "Boruta+Cox") #"SIS", "ISIS", "CausalForest+Cox",

best_alpha <- 0
n_seeds <- 10

# Define the seeds for the iterations
seeds <- seq(1, n_seeds, by = 1)

# Initialize a list to store the coefficients for each iteration
models_coefficients_list <- list()

# Create an empty dataframes to store the evaluation metrics values
c_index_df <- create_metrics_dataframes(seeds, models_names_list)
p_value_df <- create_metrics_dataframes(seeds, models_names_list)
IBS_df <- create_metrics_dataframes(seeds, models_names_list)
num_coeff_df <- create_metrics_dataframes(seeds, models_names_list)

# Memoised function to compute significant variable names
compute_significant_variable_names <- memoise::memoise(
  function(seeds, genes_expression, survival_data) {
    significant_variable_names <- list()
    
    for (i in seeds) {
      logger::log_info("Running univariate cox for seed: {i}")
      
      # Split the data
      splited <- splitTestAndTrain(genes_expression, survival_data, 0.7, i)
      
      genes_expression_train <- splited$expression_train
      survival_train <- splited$survival_train
      genes_expression_test <- splited$expression_test
      survival_test <- splited$survival_test
      
      # Run univariate Cox regression for each variable
      significant_variable_names[[i]] <- univariate_cox(survival_train, genes_expression_train, 0.05) # old 0.05
    }
    
    return(significant_variable_names)
  },
  cache = cd
)

# Call the memoised function
significant_variable_names <- compute_significant_variable_names(seeds, genes_expression, survival_data)

# Loop through the seeds and run the analysis
for (i in seeds) {
  logger::log_info("Running analysis for seed: {i}")
  
  # Split the data
  splited <- splitTestAndTrain(genes_expression, survival_data, 0.7, i)

  genes_expression_train <- splited$expression_train
  survival_train <- splited$survival_train
  genes_expression_test <- splited$expression_test
  survival_test <- splited$survival_test
  
  # reduce the genes expression data frame to only the colunmns of interest
  genes_expression_train <- genes_expression_train[, c("patient", significant_variable_names[[i]])]
  
  # Define survival object
  survival_object_train <- Surv(time = survival_train$days, event = survival_train$vital_status)
  
  # Fit models
  models_coefficients_list[[i]] <- fit_models(genes_expression_train, survival_object_train, best_alpha, survival_train)
  
  # Calculate and store C-index and IBS for each model
  a <- which(seeds == i)
  for (j in seq_along(models_coefficients_list[[i]])) {

    num_coeff_df[j, a] <- length(models_coefficients_list[[i]][[j]]$ensembl_gene_id)
    
    if (num_coeff_df[j, a] > 0) {
      
      c_index_p_value <- calculate_c_index_p_value(survival_object_train, genes_expression_train, models_coefficients_list[[i]][[j]], genes_expression_test, survival_test, survival_data)
      
      c_index_df[j, a] <- c_index_p_value$c_index
      
      p_value_df[j, a] <- c_index_p_value$p_value
      
      IBS_df[j, a] <- calculate_integrated_brier_score(survival_object_train, genes_expression_train, models_coefficients_list[[i]][[j]], genes_expression_test, survival_test)
        
      logger::log_info("seed: ", i)
      logger::log_info("c_index: ", c_index_df[j, a])
      logger::log_info("p_value: ", p_value_df[j, a])
      logger::log_info("IBS: ", IBS_df[j, a])
      
      num_coeff_df[j, a] <- length(models_coefficients_list[[i]][[j]]$ensembl_gene_id)
    } else {

      # If the model has empty coefficients, set C-index and IBS to NA
      c_index_df[j, a] <- NA
      IBS_df[j, a] <- NA
      p_value_df[j, a] <- NA
        }
    }
}

#MRR_C_Index <- calculate_MRR(c_index_df, higher_is_better = TRUE)
#MRR_IBS <- calculate_MRR(IBS_df, higher_is_better = FALSE)

# Create a summary table
summary_table <- data.frame(
  C_Index_Avg = round(apply(c_index_df, 1, mean, na.rm = TRUE), 3),
  C_Index_Std_Dev = round(apply(c_index_df, 1, sd, na.rm = TRUE), 3),
  P_value_Avg = round(apply(p_value_df, 1, mean, na.rm = TRUE), 3),
  P_value_Std_Dev = round(apply(p_value_df, 1, sd, na.rm = TRUE), 3),
  #MRR_C_Index = MRR_C_Index$MRR,
  IBS_Avg = round(apply(IBS_df, 1, mean, na.rm = TRUE), 3),
  IBS_Std_Dev = round(apply(IBS_df, 1, sd, na.rm = TRUE), 3),
  #MRR_IBS = MRR_IBS$MRR,
  Coeff_Num_Avg = round(apply(num_coeff_df, 1, mean), 1),
  Coeff_Num_Std_Dev = round(apply(num_coeff_df, 1, sd), 1),
  Non_Convergence_Perc = apply(num_coeff_df, 1, function(x) mean(x == 0) * 100)
)

#Save a summary table as a CSV file
write.csv(summary_table, file = "Results/summary_table.csv", row.names = TRUE)
print(summary_table)

#Save a p-value as a CSV file
write.csv(p_value_df, file = "Results/p_value_df.csv", row.names = TRUE)

#Save a p-value as a CSV file
write.csv(c_index_df, file = "Results/c_index_df.csv", row.names = TRUE)

# write on the chunk end time file
log_chunk_end_time("Fit and Explore the Models (train != test)", log_file = "chunk_times_log.txt")

```
# Analyse the best model (train != test)

```{r Analyse_the_best_model_different, message=FALSE, warning=FALSE}
# Identify the model with the highest average C-index
#best_model_index <- which.min(rowMeans(p_value_df, na.rm = TRUE)) 
best_model_index <- 2#which.max(rowMeans(c_index_df, na.rm = TRUE)) 
best_model_name <- rownames(c_index_df)[best_model_index]

logger::log_info("Best model:", best_model_name)
cat("Best model:", best_model_name)

seeddd <- 1 # 5 boruta, 8 RSF

# Get the coefficients of the best model
best_model_coefficients <- models_coefficients_list[[seeddd]][[best_model_index]] # o index aqui escolhido tem que bater certo com o seed do split data para que dê igual performance

# Get information on the coefficients of the best model
# gene_info_result <- getGenesInfo(best_model_coefficients)
# print(gene_info_result)

# Split the data
splited <- splitTestAndTrain(genes_expression, survival_data, 0.7, seeddd) # <- colocar o seed

genes_expression_train <- splited$expression_train
survival_train <- splited$survival_train
genes_expression_test <- splited$expression_test
survival_test <- splited$survival_test

# Define survival object
survival_object_train <- Surv(time = survival_train$days, event = survival_train$vital_status)

# Fit a Cox regression model using the covariates
fit <- coxph(survival_object_train ~ .,
             data = subset(genes_expression_train, select = best_model_coefficients$ensembl_gene_id), # specify coefficients
             init = as.numeric(best_model_coefficients$Coef_value), # specify coefficient values
             iter.max = 0) # force the software to keep those values

# Test the proportional hazards assumption for a Cox regression model fit (coxph)
#Propo_hazards <- cox.zph(fit, transform="km", terms=TRUE, singledf=FALSE, global=TRUE)
#Propo_hazards_global_p_value <- Propo_hazards$table["GLOBAL", "p"]
#print(Propo_hazards$table)

# Construct a risk score based on the linear predictor on the test data
survival_probabilities_test <- predict(fit, newdata = subset(genes_expression_test, select = best_model_coefficients$ensembl_gene_id), type = "lp")
survival_probabilities_train <- predict(fit, newdata = subset(genes_expression_train, select = best_model_coefficients$ensembl_gene_id), type = "lp")


# Visualize the distribution of the risk predictor
plot_distribution <- ggplot(data.frame(Risk_Predictor = survival_probabilities_test), aes(x = Risk_Predictor)) +
                            geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
                            geom_density(color = "red", adjust = 1.5) +
                            labs(title = "Distribution of Risk Predictor",
                                 x = "Risk Predictor (Linear Predictor)",
                                 y = "Frequency") +
                            theme_minimal()

plot_distribution

# Categorize individuals of the test data based on the median
risk <- ifelse(survival_probabilities_test > median(survival_probabilities_train), "High", "Low")

# Kaplan-Meier com a separação por High/ Low
fit_surv <- survfit(Surv(survival_test$days/365.25, survival_test$vital_status) ~ risk)
survdiff(Surv(survival_test$days/365.25, survival_test$vital_status) ~ risk)

survdiff_output <- capture.output(survdiff(Surv(survival_test$days/365.25, survival_test$vital_status) ~ risk))
plot <- ggsurvplot(fit_surv,
                   data = survival_test,
                   title = "Kaplan-Meier Curves by Risk Status",
                   xlab = "Time (years)",
                   legend.title = "Group",
                   pval = TRUE)
plot$plot


#---------------------------- AUC

#---------------------------- Cumulative case/dynamic control ROC, fonte: https://datascienceplus.com/time-dependent-roc-for-survival-prediction-models-in-r/
# The cumulative sensitivity considers those who have died by time t
# The dynamic specificity regards those who are still alive at time t
# This is one gives the prediction performance for the risk (cumulative incidence) of events over the t-year period.
Cumulative_ROC <- CumulativeCaseDynamicControlROC(survival_test, survival_probabilities_test, "Cumulative case/ Dynamic control ROC")
Cumulative_ROC

#---------------------------- Incident case/dynamic control ROC, fonte: https://datascienceplus.com/time-dependent-roc-for-survival-prediction-models-in-r/
# The incident sensitivity considers those who die at time t
# The dynamic specificity regards those who are still alive at time t
# This one gives the prediction performance for the hazard (incidence in the risk set) of events at t-year among those who are in the risk set at t.
Incident_ROC <-IncidentCaseDynamicControlROC(survival_test, survival_probabilities_test, "Incident case/ Dynamic control ROC")
Incident_ROC

#Risk AUC based on Incident case/dynamic control
plot.new()
riskAUC = risksetAUC(Stime=survival_test$days/365.25,
                     status = survival_test$vital_status,
                     marker = survival_probabilities_test,
                     method = "Cox",
                     tmax = ceiling(max(survival_test$days))/365.25,
                     type = "b",
                     plot = TRUE,
                     xlab = "Time (years)")
title(main= "AUC based on Incident case/dynamic control")
recorded_plot <- recordPlot()  # Store the plot

# Save to PDF
pdf("Results/riskAUC.pdf", width = 6, height = 4)
replayPlot(recorded_plot)
dev.off()

# Print the concordance based on the Incident Case/Dynamic Control definition (calculated as a weighted average of the area under time-specific ROC)
logger::log_info("Concordance based on Incident Case/Dynamic Control definition:", riskAUC$Cindex)

#---------------------------- UpSet plot

# Do an UpSet plot its like a veen diagram but for higher ammount of groups
genes_list <- list()
for (i in 1:n_seeds) {
  genes_list[[paste("Seed: ", i)]] <- models_coefficients_list[[i]][[best_model_index]]$ensembl_gene_id
}

# Create an UpSet plot
upset_plot <- UpSetR::upset(fromList(genes_list),nsets = n_seeds,
                    order.by = "degree", mb.ratio = c(0.5,0.50))
plot.new()
upset_plot
recorded_plot <- recordPlot()  # Store the plot

# save the plot
pdf("Results/upset_plot.pdf", width = 8, height = 3) # Create a PDF file to save the plot
replayPlot(recorded_plot)
dev.off() # to save the plot above
replayPlot(recorded_plot)

#---------------------------- Make a table with the genes that are in more than 1 seed

df_genes_in_multiple_seeds <- get_gene_counts_with_names(genes_list)
print(df_genes_in_multiple_seeds) # Display the data frame

# Save a predictors genes and coefficients as a CSV file
#write.csv(Propo_hazards$table, file = "Results/Propo_hazards", row.names = TRUE)

# Save a predictors genes and coefficients as a CSV file
# write.csv(gene_info_result, file = "Results/predictors_genes_and_coefficients", row.names = FALSE)

# Write the captured output to a file
writeLines(survdiff_output, "Results/survdiff_output.txt")

# Save the concordance based on the Incident Case/Dynamic Control definition (calculated as a weighted average of the area under time-specific ROC)
write.csv(riskAUC$Cindex, file = "Results/concordance_IncidentCaseDynamicControlROC", row.names = FALSE)


# Save the table with the genes that are in more than 1 seed
write.csv(df_genes_in_multiple_seeds, file = "Results/df_genes_in_multiple_seeds", row.names = FALSE)


# Save plots
ggsave(filename = "Results/plot_high_low_risk.pdf", plot = plot$plot, width = 6, height = 4)
ggsave(filename = "Results/Cumulative_ROC.pdf", plot = Cumulative_ROC, width = 6, height = 4)
ggsave(filename = "Results/Incident_ROC.pdf", plot = Incident_ROC, width = 6, height = 4)
ggsave(filename = "Results/distribution_of_risk_predictor.pdf", plot = plot_distribution, width = 6, height = 4)


# write on the chunk end time file
log_chunk_end_time("Analyse the best model (train != test)", log_file = "chunk_times_log.txt")
```

# Fit and Explore the Models (train = test)

```{r Fit_and_Explore_the_Models_equal, message=FALSE, warning=FALSE}

# Models' names
models_names_list <- c("Cox", "RandomForest+Cox", "Boruta+Cox") # "CausalForest+Cox", "SIS", "ISIS"

best_alpha <- 0
n_seeds_all_equal <- 1

# Define the seeds for the iterations
seeds_all_equal <- 1

# Initialize a list to store the coefficients for each iteration
models_coefficients_list_all_equal <- list()

# Create an empty dataframe to store the evaluation metrics values
c_index_df_all_equal <- create_metrics_dataframes(seeds_all_equal, models_names_list)
p_value_df_all_equal <- create_metrics_dataframes(seeds_all_equal, models_names_list)
IBS_df_all_equal <- create_metrics_dataframes(seeds_all_equal, models_names_list)
num_coeff_df_all_equal <- create_metrics_dataframes(seeds_all_equal, models_names_list)

# Loop through the seeds and run the analysis
i <- seeds_all_equal
logger::log_info("Running analysis for seed:", seeds_all_equal[i])

genes_expression_train <- genes_expression
survival_train <- survival_data
genes_expression_test <- genes_expression
survival_test <- survival_data
  
# Run univariate Cox regression for each variable
significant_variable_names <- univariate_cox(survival_train, genes_expression_train, 0.05) #old 0.05

# reduce the genes expression data frame to only the colunmns of interest
genes_expression_train <- genes_expression_train[, c("patient", significant_variable_names)]
  
# Define survival object
survival_object_train <- Surv(time = survival_train$days, event = survival_train$vital_status)
  
# Fit models
models_coefficients_list_all_equal[[i]] <- fit_models(genes_expression_train, survival_object_train, best_alpha, survival_train)
  
# Calculate and store C-index for each model
a <- which(seeds == i)
for (j in seq_along(models_coefficients_list_all_equal[[i]])) {
    
 num_coeff_df_all_equal[j, a] <- length(models_coefficients_list_all_equal[[i]][[j]]$ensembl_gene_id)
    
 if (num_coeff_df_all_equal[j, a] > 0) {
      
  c_index_p_value_all_equal <- calculate_c_index_p_value(survival_object_train, genes_expression_train, models_coefficients_list_all_equal[[i]][[j]], genes_expression_test, survival_test, survival_data)
      
  c_index_df_all_equal[j, a] <- c_index_p_value_all_equal$c_index
      
  p_value_df_all_equal[j, a] <- c_index_p_value_all_equal$p_value
      
  IBS_df_all_equal[j, a] <- calculate_integrated_brier_score(survival_object_train, genes_expression_train, models_coefficients_list_all_equal[[i]][[j]], genes_expression_test, survival_test)
        
  logger::log_info("seed: ", seeds_all_equal[i])
  logger::log_info("c_index: ", c_index_df_all_equal[j, a])
  logger::log_info("p_value: ", p_value_df_all_equal[j, a])
  logger::log_info("IBS: ", IBS_df_all_equal[j, a])
  num_coeff_df_all_equal[j, a] <- length(models_coefficients_list_all_equal[[i]][[j]]$ensembl_gene_id)
    
    } else {
      
    # If the model has empty coefficients, set C-index to NA 
    c_index_df_all_equal[j, a] <- NA
    p_value_df_all_equal[j, a] <- NA
    IBS_df_all_equal[j, a] <- NA
         }
  }



# Create a summary table
summary_table_all_equal <- data.frame(
  C_Index_Avg = round(apply(c_index_df_all_equal, 1, mean, na.rm = TRUE), 3),
  C_Index_Std_Dev = round(apply(c_index_df_all_equal, 1, sd, na.rm = TRUE), 3),
  P_value_Avg = round(apply(p_value_df_all_equal, 1, mean, na.rm = TRUE), 3),
  P_value_Std_Dev = round(apply(p_value_df_all_equal, 1, sd, na.rm = TRUE), 3),
  IBS_Avg = round(apply(IBS_df_all_equal, 1, mean, na.rm = TRUE), 3),
  IBS_Std_Dev = round(apply(IBS_df_all_equal, 1, sd, na.rm = TRUE), 3),
  Coeff_Num_Avg = round(apply(num_coeff_df_all_equal, 1, mean), 1),
  Coeff_Num_Std_Dev = round(apply(num_coeff_df_all_equal, 1, sd), 1),
  Non_Convergence_Perc = apply(num_coeff_df_all_equal, 1, function(x) mean(x == 0) * 100)
)

#Save a summary table as a CSV file
write.csv(summary_table_all_equal, file = "Results/summary_table_all_equal.csv", row.names = TRUE)

print(summary_table_all_equal)

# write on the chunk end time file
log_chunk_end_time("Fit and Explore the Models (train = test)", log_file = "chunk_times_log.txt")
```


# Analyse the best model (train = test)

```{r Analyse_the_best_model_equal, message=FALSE, warning=FALSE}
# Identify the model with the highest average C-index
#best_model_index_all_equal <- which.max(rowMeans(c_index_df_all_equal, na.rm = TRUE)) 
best_model_index_all_equal <- 2#which.min(rowMeans(p_value_df_all_equal, na.rm = TRUE)) 
best_model_name_all_equal <- rownames(p_value_df_all_equal)[best_model_index_all_equal]

logger::log_info("Best model:", best_model_name_all_equal)
cat("Best model:", best_model_name_all_equal)

# Get the coefficients of the best model
best_model_coefficients_all_equal <- models_coefficients_list_all_equal[[1]][[best_model_index_all_equal]] # o index aqui escolhido tem que bater certo com o seed do split data para que dê igual performance

# Get information on the coefficients of the best model
# gene_info_result_all_equal <- getGenesInfo(best_model_coefficients_all_equal)
# print(gene_info_result_all_equal)

# Split the data
set.seed(1)
#splited <- splitTestAndTrain(genes_expression, survival_data, 0.7)

genes_expression_train <- genes_expression
survival_train <- survival_data
genes_expression_test <- genes_expression
survival_test <- survival_data

# Define survival object
survival_object_train <- Surv(time = survival_train$days, event = survival_train$vital_status)

# Fit a Cox regression model using the covariates
fit <- coxph(survival_object_train ~ .,
             data = subset(genes_expression_train, select = best_model_coefficients_all_equal$ensembl_gene_id), # specify coefficients
             init = as.numeric(best_model_coefficients_all_equal$Coef_value), # specify coefficient values
             iter.max = 0) # force the software to keep those values

# Test the proportional hazards assumption for a Cox regression model fit (coxph)
#Propo_hazards_all_equal <- cox.zph(fit, transform="km", terms=TRUE, singledf=FALSE, global=TRUE)
#Propo_hazards_global_p_value_all_equal <- Propo_hazards_all_equal$table["GLOBAL", "p"]
#print(Propo_hazards_all_equal$table)

# Construct a risk score based on the linear predictor on the test data
survival_probabilities_test <- predict(fit, newdata = subset(genes_expression_test, select = best_model_coefficients_all_equal$ensembl_gene_id), type = "lp") 


# Visualize the distribution of the risk predictor
plot_distribution_all_equal <- ggplot(data.frame(Risk_Predictor = survival_probabilities_test), aes(x = Risk_Predictor)) +
                            geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
                            geom_density(color = "red", adjust = 1.5) +
                            labs(title = "Distribution of Risk Predictor",
                                 x = "Risk Predictor (Linear Predictor)",
                                 y = "Frequency") +
                            theme_minimal()

plot_distribution_all_equal

# Categorize individuals of the test data based on the median
risk <- ifelse(survival_probabilities_test > median(survival_probabilities_test), "High", "Low")

# Kaplan-Meier com a separação por High/ Low
fit_surv <- survfit(Surv(survival_test$days/365.25, survival_test$vital_status) ~ risk)
survdiff(Surv(survival_test$days/365.25, survival_test$vital_status) ~ risk)

survdiff_output_all_equal <- capture.output(survdiff(Surv(survival_test$days/365.25, survival_test$vital_status) ~ risk))
plot_all_equal <- ggsurvplot(fit_surv,
                   data = survival_test,
                   title = "Kaplan-Meier Curves by Risk Status",
                   xlab = "Time (years)",
                   legend.title = "Group",
                   pval = TRUE)
plot_all_equal$plot

# Extract median survival time for each group
median_survival <- data.frame(
  group = names(fit_surv$strata),  # Group names
  median_survival_time = sapply(1:length(fit_surv$strata), function(i) {
    surv_summary <- summary(fit_surv, times = fit_surv$time)
    if (!is.na(surv_summary$table[i, "median"])) {
      surv_summary$table[i, "median"]  # Median survival time
    } else {
      NA  # If no median is found
    }
  })
)

# View the median survival times
print(median_survival)


#---------------------------- AUC

#---------------------------- Cumulative case/dynamic control ROC, fonte: https://datascienceplus.com/time-dependent-roc-for-survival-prediction-models-in-r/
# The cumulative sensitivity considers those who have died by time t
# The dynamic specificity regards those who are still alive at time t
# This is one gives the prediction performance for the risk (cumulative incidence) of events over the t-year period.
Cumulative_ROC_all_equal <- CumulativeCaseDynamicControlROC(survival_test, survival_probabilities_test, "Cumulative case/ Dynamic control ROC")
Cumulative_ROC_all_equal

#---------------------------- Incident case/dynamic control ROC, fonte: https://datascienceplus.com/time-dependent-roc-for-survival-prediction-models-in-r/
# The incident sensitivity considers those who die at time t
# The dynamic specificity regards those who are still alive at time t
# This one gives the prediction performance for the hazard (incidence in the risk set) of events at t-year among those who are in the risk set at t.
Incident_ROC_all_equal <-IncidentCaseDynamicControlROC(survival_test, survival_probabilities_test, "Incident case/ Dynamic control ROC")
Incident_ROC_all_equal

#Risk AUC based on Incident case/dynamic control
plot.new()
riskAUC_all_equal = risksetAUC(Stime=survival_test$days/365.25,
                     status = survival_test$vital_status,
                     marker = survival_probabilities_test,
                     method = "Cox",
                     tmax = ceiling(max(survival_test$days))/365.25,
                     type = "b",
                     plot = TRUE,
                     xlab = "Time (years)")
title(main= "AUC based on Incident case/dynamic control")
recorded_plot <- recordPlot()  # Store the plot

# Save to PDF
pdf("Results/riskAUC_all_equal.pdf", width = 6, height = 4) # to save the plot below
replayPlot(recorded_plot)
dev.off() # to save the plot above

# Print the concordance based on the Incident Case/Dynamic Control definition (calculated as a weighted average of the area under time-specific ROC)
logger::log_info("Concordance based on Incident Case/Dynamic Control definition:", riskAUC_all_equal$Cindex)

# #---------------------------- UpSet plot
# 
# # Do an UpSet plot its like a veen diagram but for higher ammount of groups
# genes_list_all_equal <- list()
# for (i in 1:n_seeds_all_equal) {
#   genes_list_all_equal[[paste("Seed: ", i)]] <- models_coefficients_list_all_equal[[i]][[best_model_index_all_equal]]$ensembl_gene_id
# }
# 
# # Create an UpSet plot
# upset_plot_all_equal <- upset(fromList(genes_list_all_equal),nsets = n_seeds_all_equal, order.by = "degree")
# 
# # save the plot
# pdf("Results/upset_plot_all_equal.pdf", width = 6, height = 5, onefile=FALSE) # Create a PDF file to save the plot
# upset_plot_all_equal
# # Add a white rectangle behind the title
# grid.rect(x = 0.5, y = 0.95, width = 0.8, height = 0.1, gp = gpar(fill = "white", col = NA))
# # Add a title using grid.text()
# grid.text("Genes Selected Across 10 Different Seeds", x = 0.5, y = 0.95, gp = gpar(fontsize = 16, fontface = "bold", fill = "white"))
# dev.off() # to save the plot above
# 
# #---------------------------- Make a table with the genes that are in more than 1 seed
# 
# df_genes_in_multiple_seeds_all_equal <- get_gene_counts_with_names(genes_list_all_equal)
# print(df_genes_in_multiple_seeds_all_equal) # Display the data frame


# Save a predictors genes and coefficients as a CSV file
#write.csv(Propo_hazards_all_equal$table, file = "Results/Propo_hazards_all_equal", row.names = TRUE)

# # Save a predictors genes and coefficients as a CSV file
# write.csv(gene_info_result_all_equal, file = "Results/predictors_genes_and_coefficients_all_equal", row.names = FALSE)

# Write the captured output to a file
writeLines(survdiff_output_all_equal, "Results/survdiff_output_all_equal.txt")

# Save the concordance based on the Incident Case/Dynamic Control definition (calculated as a weighted average of the area under time-specific ROC)
write.csv(riskAUC_all_equal$Cindex, file = "Results/concordance_IncidentCaseDynamicControlROC_all_equal", row.names = FALSE)


# # Save the table with the genes that are in more than 1 seed
# write.csv(df_genes_in_multiple_seeds_all_equal, file = "Results/df_genes_in_multiple_seeds_all_equal", row.names = FALSE)


# Save plots
ggsave(filename = "Results/plot_high_low_risk_all_equal.pdf", plot = plot_all_equal$plot, width = 6, height = 4)
ggsave(filename = "Results/Cumulative_ROC_all_equal.pdf", plot = Cumulative_ROC_all_equal, width = 6, height = 4)
ggsave(filename = "Results/Incident_ROC_all_equal.pdf", plot = Incident_ROC_all_equal, width = 6, height = 4)
ggsave(filename = "Results/distribution_of_risk_predictor_all_equal.pdf", plot = plot_distribution_all_equal, width = 6, height = 4)


# write on the chunk end time file
log_chunk_end_time("Analyse the best model (train = test)", log_file = "chunk_times_log.txt")
```

# Enrichment Analysis

```{r Enrichment_Analysis, warning=FALSE}

#print(best_model_coefficients_all_equal)

# Extract ensembl_gene_id from the first entries of each sublist
ensembl_ids <- lapply(models_coefficients_list, function(x) x[[best_model_index]]$ensembl_gene_id)

# Combine all the IDs into a single vector
ensembl_ids_combined <- unique(unlist(ensembl_ids, use.names = FALSE))

                                  
# Remove the version of the gene from its name(everything after the dot including the dot)
#genesss <- sub("\\..*", "", best_model_coefficients_all_equal$ensembl_gene_id)
genesss <- sub("\\..*", "", ensembl_ids_combined)

# Convert Ensembl IDs to Entrez IDs
genes_list <- bitr(genesss,
                    fromType = "ENSEMBL",  # Input type is Ensembl Gene IDs
                    toType = "ENTREZID",   # Convert to Entrez Gene IDs
                    OrgDb = org.Hs.eg.db)  # Database for human genes

# GO Enrichment Analysis
go_enrichment <- enrichGO(gene          = genes_list$ENTREZID,
                          OrgDb         = org.Hs.eg.db)#,
                          #keyType       = "ENTREZID",  # The type of gene identifier
                          #ont           = "ALL",      # "BP", "MF", "CC", or "ALL" for all three
                          #pAdjustMethod = "BH",       # Adjust p-values using Benjamini-Hochberg
                          #pvalueCutoff  = 0.05,       # p-value threshold
                          #qvalueCutoff  = 0.02)        # q-value (FDR) threshold


# KEGG Pathway Enrichment Analysis
kegg_enrichment <- enrichKEGG(gene         = genes_list$ENTREZID,
                              organism     = 'hsa')        # "hsa" for human genes
                              #pvalueCutoff = 0.05)


# Dot plot for GO enrichment results if results are found
if (nrow(as.data.frame(go_enrichment)) > 0) {
  dotplot(go_enrichment, showCategory = 10)  # Show top 10 GO terms
} else {
  cat("No enriched GO terms to plot.")
}

# Dot plot for GO enrichment results if results are found
if (nrow(as.data.frame(kegg_enrichment)) > 0) {
  dotplot(kegg_enrichment, showCategory = 10)  # Show top 10 GO terms
} else {
  cat("No enriched KEGG terms to plot.")
}

# write on the chunk end time file
log_chunk_end_time("Enrichment Analysis", log_file = "chunk_times_log.txt")
```

<!-- # Indentify oultiers with the rank product test -->

<!-- ```{r Indentify_oultiers_with_the_rank_product_test, message=FALSE, warning=FALSE} -->
<!-- # Calculate martingale residuals for each model -->
<!-- martingale_residuals_matrix <- calculate_martingale_residuals(models_coefficients_list, genes_expression, survival_data) -->

<!-- rank_product_results <- calculate_rank_product(martingale_residuals_matrix) -->

<!-- # p-values calculation -->

<!-- rho = rank_product_results #rank product matrix result -->
<!-- n <-dim(survival_data)[1] # number of samples -->
<!-- k <-sum(sapply(unlist(models_coefficients_list, recursive = FALSE), function(df) nrow(df) > 0)) # number of models with coefficients different than zero -->

<!-- pvalues <- as.vector(rankprodbounds(rho,n,k,Delta ='upper')) # The p-values are obtained by the following, where Delta option is the geometric mean. -->

<!-- # Ensure all p-values are within the [0, 1] range: Even though the values should be in this range, sometimes very small floating-point errors can cause issues -->
<!-- #pvalues <- pmin(pmax(pvalues, 0), 1) -->

<!-- # q-values calculation -->
<!-- qvalues <- p.adjust(pvalues, method = "BH") -->

<!-- outliers_rank_product <- which(qvalues<0.05) # Tightened the significance threshold to q-values < 0.001, instead of 0.05, to focus on the most significant outliers, reducing the number of outliers for more robust model evaluation. -->

<!-- # Remove the rows corresponding to outliers  -->
<!-- genes_expression_without_outliers <- genes_expression[-outliers_rank_product, ] -->
<!-- survival_data_without_outliers <- survival_data[-outliers_rank_product, ] -->

<!-- ## Kaplan-Meier Curves for Both Before and After Outlier Removal -->

<!-- # Combine the datasets and create the grouping variable -->
<!-- combined_survival_data <- rbind( -->
<!--   data.frame(survival_data, group = "With Outliers"), -->
<!--   data.frame(survival_data_without_outliers, group = "Without Outliers") -->
<!-- ) -->

<!-- # Fit Kaplan-Meier survival model using the combined dataset -->
<!-- fit_km_before_after <- survfit(Surv(days, vital_status) ~ group, data = combined_survival_data) -->
<!-- survdiff(Surv(days, vital_status) ~ group, data = combined_survival_data) -->

<!-- # Create a combined Kaplan-Meier plot with both before and after curves -->
<!-- km_before_after <- ggsurvplot(fit_km_before_after, -->
<!--                               data = combined_survival_data, -->
<!--                               title = "Kaplan-Meier Curves Pre and Post Outlier Removal", -->
<!--                               xlab = "Time (days)", -->
<!--                               ylab = "Survival Probability", -->
<!--                               legend.title = "Group", -->
<!--                               risk.table = TRUE, -->
<!--                               pval = TRUE) -->

<!-- km_before_after$plot -->

<!-- survdiff_km_before_after_output <- capture.output(survdiff(Surv(days, vital_status) ~ group, data = combined_survival_data)) -->

<!-- # Create the table with the specified information -->
<!-- outliers_table <- data.frame( -->
<!--   Index = outliers_rank_product, -->
<!--   Time = survival_data$days[outliers_rank_product], -->
<!--   Status = survival_data$vital_status[outliers_rank_product], -->
<!--   p_value = pvalues[outliers_rank_product], -->
<!--   q_value = qvalues[outliers_rank_product] -->
<!-- ) -->

<!-- # Order the table by q-value -->
<!-- outliers_table <- outliers_table[order(outliers_table$q_value), ] -->

<!-- # Print the table to check -->
<!-- print(outliers_table) -->


<!-- # Write the captured output to a file -->
<!-- writeLines(survdiff_km_before_after_output, "Results/survdiff_Before_After_Outliers_Removal.txt") -->

<!-- # Save plot -->
<!-- ggsave(filename = "Results/KM_Curve_Before_After_Outliers_Removal.pdf", plot = km_before_after$plot, width = 6, height = 4) -->

<!-- # Save the table as a CSV file in the "Results" directory -->
<!-- write.csv(outliers_table, file = "Results/outliers_table.csv", row.names = FALSE) -->

<!-- # write on the chunk end time file -->
<!-- log_chunk_end_time("Indentify oultiers with the rank product test", log_file = "chunk_times_log.txt") -->
<!-- ``` -->

<!-- # Fit and Explore the Models Without Outliers -->

<!-- ```{r Fit_and_Explore_the_Models_Without_Outliers, message=FALSE, warning=FALSE} -->

<!-- # Initialize a list to store the coefficients for each iteration -->
<!-- models_coefficients_list_without_outliers <- list() -->

<!-- # Create an empty dataframe to store C-index values -->
<!-- num_models <- length(models_names_list) # Assuming each iteration has the same number of models -->
<!-- c_index_df_without_outliers <- data.frame(matrix(ncol = length(seeds), nrow = num_models)) -->
<!-- colnames(c_index_df_without_outliers) <- paste("Seed_", seeds) -->
<!-- rownames(c_index_df_without_outliers) <- models_names_list -->

<!-- # Create an empty dataframe to store the number of coefficients -->
<!-- num_coeff_df_without_outliers <- data.frame(matrix(ncol = length(seeds), nrow = num_models)) -->
<!-- colnames(num_coeff_df_without_outliers) <- paste("Seed_", seeds) -->
<!-- rownames(num_coeff_df_without_outliers) <- models_names_list -->


<!-- # Loop through the seeds and run the analysis -->
<!-- for (i in seq_along(seeds)) { -->
<!--   cat("Running analysis for seed:", seeds[i], "\n") -->

<!--   # Split the data -->
<!--   set.seed(i) -->
<!--   splited <- splitTestAndTrain(genes_expression_without_outliers, survival_data_without_outliers, 0.7) -->

<!--   genes_expression_train <- splited$expression_train -->
<!--   survival_train <- splited$survival_train -->
<!--   genes_expression_test <- splited$expression_test -->
<!--   survival_test <- splited$survival_test -->

<!--   # Run univariate Cox regression for each variable -->
<!--   significant_variable_names <- univariate_cox(survival_train, genes_expression_train, 0.05) -->

<!--   # reduce the genes expression data frame to only the colunmns of interest -->
<!--   genes_expression_train <- genes_expression_train[, c("patient", significant_variable_names)] -->
<!--   print(ncol(genes_expression_train)) -->

<!--   # Define survival object -->
<!--   survival_object_train <- Surv(time = survival_train$days, event = survival_train$vital_status) -->

<!--   # Fit models -->
<!--   models_coefficients_list_without_outliers[[i]] <- fit_models(genes_expression_train, survival_object_train, best_alpha, survival_train) -->

<!--   # Calculate and store C-index for each model -->

<!--   for (j in seq_along(models_coefficients_list_without_outliers[[i]])) { -->

<!--     num_coeff_df_without_outliers[j, i] <- length(models_coefficients_list_without_outliers[[i]][[j]]$ensembl_gene_id) -->

<!--     if (num_coeff_df_without_outliers[j, i] > 0) { -->

<!--       c_index_df_without_outliers[j, i] <- calculate_c_index(survival_object_train, genes_expression_train, models_coefficients_list_without_outliers[[i]][[j]], genes_expression_test, survival_test, survival_data) -->

<!--       num_coeff_df_without_outliers[j, i] <- length(models_coefficients_list_without_outliers[[i]][[j]]$ensembl_gene_id) -->
<!--     } else { -->
<!--       # If the model has empty coefficients, set C-index to NA -->
<!--       c_index_df_without_outliers[j, i] <- NA -->
<!--            } -->
<!--     } -->
<!-- } -->

<!-- # Create a summary table -->
<!-- summary_table_without_outliers <- data.frame( -->
<!--   C_Index_Avg = round(apply(c_index_df_without_outliers, 1, mean, na.rm = TRUE), 3), -->
<!--   C_Index_Std_Dev = round(apply(c_index_df_without_outliers, 1, sd, na.rm = TRUE), 3), -->
<!--   Coeff_Num_Avg = round(apply(num_coeff_df_without_outliers, 1, mean), 1), -->
<!--   Coeff_Num_Std_Dev = round(apply(num_coeff_df_without_outliers, 1, sd), 1), -->
<!--   Non_Convergence_Perc = apply(num_coeff_df_without_outliers, 1, function(x) mean(x == 0) * 100) -->
<!-- ) -->

<!-- # Save a summary table as a CSV file -->
<!-- write.csv(summary_table_without_outliers, file = "Results/summary_table_without_outliers.csv", row.names = TRUE) -->

<!-- print(summary_table_without_outliers) -->

<!-- # write on the chunk end time file -->
<!-- log_chunk_end_time("Fit and Explore the Models Without Outliers", log_file = "chunk_times_log.txt") -->
<!-- ``` -->


<!-- # Analyse the balance of censored data in test and training -->

<!-- ```{r Analyse_the_balance_of_censored_data_in_test_and_training} -->

<!-- counts_test <- table(survival_test$vital_status) -->

<!-- # Calculate the percentage of zeros and ones -->
<!-- test_percent_zeros <- round((counts_test[1] / sum(counts_test)) * 100, 2) -->
<!-- test_percent_ones <- round((counts_test[2] / sum(counts_test)) * 100, 2) -->

<!-- counts_train <- table(survival_train$vital_status) -->

<!-- # Calculate the percentage of zeros and ones -->
<!-- train_percent_zeros <- round((counts_train[1] / sum(counts_train)) * 100, 2) -->
<!-- train_percent_ones <- round((counts_train[2] / sum(counts_train)) * 100, 2) -->

<!-- # Create a dataframe to store the comparison -->
<!-- comparison_test_train_data <- data.frame( -->
<!--   Dataframe = c("survival_test", "survival_train"), -->
<!--   Alive = c(test_percent_zeros, train_percent_zeros), -->
<!--   Dead = c(test_percent_ones, train_percent_ones) -->
<!-- ) -->

<!-- comparison_test_train_data -->

<!-- # Save the table as a CSV file in the "Results" directory -->
<!-- write.csv(comparison_test_train_data, file = "Results/comparison_test_train_data.csv", row.names = FALSE) -->

<!-- ``` -->

<!-- # Test the best model on the train data -->

<!-- ```{r Test_the_best_model_on_the_train_data} -->

<!-- # Construct a risk score based on the linear predictor on the train data -->
<!-- a_survival_probabilities_train <- predict(fit, newdata = subset(genes_expression_train, select = best_model_coefficients$ensembl_gene_id), type = "lp") -->

<!-- # Categorize individuals of the test data based on the median -->
<!-- risk_groups <- ifelse(a_survival_probabilities_train > median(a_survival_probabilities_train), "High", "Low") -->

<!-- # Kaplan-Meier com a separação por High/ Low -->
<!-- fit_surv <- survfit(Surv(survival_train$days, survival_train$vital_status) ~ risk_groups) -->
<!-- survdiff(Surv(survival_train$days, survival_train$vital_status) ~ risk_groups) -->
<!-- survdiff_output_train_data <- capture.output(survdiff(Surv(survival_train$days, survival_train$vital_status) ~ risk_groups)) -->

<!-- plot_train_data <- ggsurvplot(fit_surv, data = survival_train, title = "Kaplan-Meier Curves by Risk Status (train data)", legend.title = "Group", pval = TRUE) -->
<!-- plot_train_data$plot -->


<!-- # Write the captured output to a file -->
<!-- writeLines(survdiff_output_train_data, "Results/survdiff_output_train_data.txt") -->

<!-- # Save plot -->
<!-- ggsave(filename = "Results/plot_high_low_risk_train_data.pdf", plot = plot_train_data$plot, width = 6, height = 4) -->

<!-- ``` -->

# Snaphot the packages installed

```{r Snapshot_packages, results = 'hide', message=FALSE, warning=FALSE}
#renv::snapshot()
```
