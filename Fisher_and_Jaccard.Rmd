---
title: "Glioma biomarkers to distinguish high-risk from low-risk patients"
author: "Beatriz N. Leitão, André Veríssimo, Alexandra M. Carvalho and Susana Vinga"
date: "March, 2025"
output:
  html_document: 
    number_sections: yes
    toc: yes
editor_options:
  chunk_output_type: inline
---

```{r init, include=FALSE}

# Trick to store functions in search path, but not enviromnent
local({
  env <- new.env()
  env$fun_source <- function(file_name) {
    env_name <- sprintf("my_functions:%s", gsub(" ", "_", basename(file_name)))
    if (env_name %in% search()) {
      detach(env_name, character.only = TRUE, unload = TRUE)
    }
    sys.source(file_name, envir = attach(NULL, name = env_name))
  }
  lapply(search()[search() %in% "fun_source"], detach, character.only = TRUE, unload = TRUE)
  attach(env, name = "fun_source")
})

# Run garbage colector after each chunk
knitr::knit_hooks$set(
  after_chunk = function(options) {
    invisible(gc())
  }
)
```

# Install packages

```{r Install_packages, results = 'hide', message=FALSE, warning=FALSE}
#renv::restore()
```

# Load libraries

```{r Load_libraries, results=FALSE, message=FALSE, warning=FALSE}
library(TCGAbiolinks)
library(dplyr)
library(tibble)
# library(tidyverse)
library(DT)
library(SummarizedExperiment)
library(survival)
library(survminer)
# library(readr)
library(glmnet)
library(caret)
library(openxlsx)
library(biomaRt)
library(writexl)
library(edgeR)
library(pROC)
library(caTools)
library(survivalROC)
library(risksetROC)
library(lattice)
library(survMisc)
library(SIS)
library(VennDiagram)
# library(glmSparseNet)
library(randomForestSRC)
library(grf)
library(Boruta)
library(timeROC)
library(qvalue)
library(clusterProfiler)
library(org.Hs.eg.db)
library(enrichplot)
library(ReactomePA)
library(STRINGdb)
library(pathview)
library(UpSetR)
library(rsample)
library(pec)
```

# Prepare the environment, report chunk status and sessioninfo

```{r Prepare_the_environment_report_chunk_status_and_sessioninfo}

# clean current environment
rm(list = ls())

# Capture the sessionInfo() output and write it to a file
writeLines(capture.output(sessionInfo()), con = "sessioninfo.txt")

fun_source("Functions/Logger.R")

# write on the chunk end time file
log_chunk_end_time("Prepare the environment, report chunk status and sessioninfo", log_file = "chunk_times_log.txt")
```

# Download functions

```{r Download_functions}
# download the functions
fun_source("Functions/Data_preparation.R")
fun_source("Functions/Model_evaluation.R")
fun_source("Functions/Model_fitting.R")

# write on the chunk end time file
log_chunk_end_time("Download functions", log_file = "chunk_times_log.txt")
```

# Folder to store results

```{r Folder_to_store_results}

# Ensure the 'Results' directory exists
if (!dir.exists("Results_Fisher_Jaccard")) {
  dir.create("Results_Fisher_Jaccard")
}

# write on the chunk end time file
log_chunk_end_time("Folder to store results", log_file = "chunk_times_log.txt")
```

# Download data

```{r Download_data, results = 'hide', message=FALSE, warning=FALSE}
# Cache to use in memoise
cd <- cachem::cache_disk(here::here(".", "memoise-cache"), max_size = 3 * 1024^3)

# download_data <- memoise::memoise(
#   function() {
#     query_RNA <- TCGAbiolinks::GDCquery(
#       project = c("TCGA-GBM", "TCGA-LGG"),
#       data.category = "Transcriptome Profiling",
#       data.type = "Gene Expression Quantification",
#       workflow.type = "STAR - Counts",
#       experimental.strategy = ("RNA-Seq")
#     )
#     # Check if files exist before downloading
#     if (!dir.exists("GDCdata")) {
#       TCGAbiolinks::GDCdownload(query = query_RNA)
#     }
# 
#     TCGAbiolinks::GDCprepare(query = query_RNA)
#   },
#   cache = cd
# )
# 
# TCGA_RNA <- download_data()
# saveRDS(TCGA_RNA, file = "TCGA_RNA.rds")

library(googledrive)

# Ensure that we don't use authentication (for public files)
drive_deauth()

# Now download the file directly
drive_download(as_id("1UkGI-yjHDu_HQFL4dmwW-T9vde2JnD3J"), 
               path = "TCGA_RNA.rds", 
               overwrite = TRUE)

TCGA_RNA <- readRDS("TCGA_RNA.rds")

# query_RNA <- TCGAbiolinks::GDCquery(
#   project = c("TCGA-GBM", "TCGA-LGG"),
#   data.category = "Transcriptome Profiling",
#   data.type = "Gene Expression Quantification",
#   workflow.type = "STAR - Counts",
#   experimental.strategy = "RNA-Seq"
# )
# 
# if (!dir.exists("GDCdata")) {  
#   TCGAbiolinks::GDCdownload(query = query_RNA)  
# }
# 
# download_data <- memoise::memoise(
#   function() {
#     TCGAbiolinks::GDCprepare(query = query_RNA)  # ✅ This is the only step cached
#   },
#   cache = cd  # ✅ Persistent caching
# )
# 
# TCGA_RNA <- download_data()


# write on the chunk end time file
log_chunk_end_time("Download data", log_file = "chunk_times_log.txt")
```

# Prepare survival data

```{r Prepare_survival_data}
# Extract survival data of interest
columns_to_extract <- c("patient", "project_id", "vital_status", "days_to_death", "days_to_last_follow_up")
survival_data <- createSurvivalDataFrame(columns_to_extract, TCGA_RNA)


# Clean and prepare survival data
survival_data <- cleanSurvivalData(survival_data)

# write on the chunk end time file
log_chunk_end_time("Prepare survival data", log_file = "chunk_times_log.txt")
```

# Assign a new classification to the data

```{r Assign_new_classification_to_the_data, results = 'hide', message=FALSE, warning=FALSE}
# new classification -->
new_classification <- readr::read_csv("SIMPLIFIED_CLASSIFICATION_TCGA_2016_2021.csv") #download the classification datafram
names(new_classification)[names(new_classification) == "Patient_ID"] <- "patient" # remane the Patient_ID column
new_classification <- subset(new_classification, select = -c(TCGA.histological.type, classification.2016)) # delete unnecessary columns

# Merge the dataframes to add the disease information keeping only common patients
survival_data <- merge(survival_data, new_classification, by = "patient")
survival_data <- subset(survival_data, select = -project_id) # remove old classification
names(survival_data)[names(survival_data) == "classification.2021"] <- "project_id" # aplly the old name to the new classification


# write on the chunk end time file
log_chunk_end_time("Assign a new classification to the data", log_file = "chunk_times_log.txt")
```

# Select and prepare expression data

```{r Select_and_prepare_expression_data}
# Extrair dataframe com a expressão dos genes de interesse
genes_expression <- createGeneExpressionDataframe("protein_coding", "unstranded", TCGA_RNA, survival_data)
#genes_expression <- createGeneExpressionDataframe("lncRNA", "unstranded", TCGA_RNA, survival_data)
#genes_expression <- createGeneExpressionDataframe("miRNA", "unstranded", TCGA_RNA, survival_data)       #<------------ indicar os dados 

# Clean the gene expression dataframe
genes_expression <- cleanGeneExpressionData(genes_expression)

# write on the chunk end time file
log_chunk_end_time("Select and prepare expression data", log_file = "chunk_times_log.txt")
```

```{r clean_up_tgca_rna, include=FALSE}
rm(TCGA_RNA)
log_chunk_end_time("Clean-up TGCGA RNA", log_file = "chunk_times_log.txt")
```


# Disease selection and data normalization

```{r Disease_selection_and_data_normalization}

#------------ OLD CLASSIFICATION-------------------------------------------------

# selecionar apenas os dados da doença de interesse
#data <- selectDataPerDisease("TCGA-GBM", genes_expression, survival_data)
#data <- selectDataPerDisease("TCGA-LGG", genes_expression, survival_data)                                   

#------------ NEW CLASSIFICATION-------------------------------------------------

#data <- selectDataPerDisease("astrocytoma", genes_expression, survival_data)
data <- selectDataPerDisease("glioblastoma", genes_expression, survival_data)
#data <- selectDataPerDisease("oligodendroglioma", genes_expression, survival_data)

genes_expression <- data$genes_expression
survival_data <- data$survival_data

# remove genes where the sum of the gene expression is 0 (necessary to repeat this step, since there is a selection of patients) 
genes_expression <- cleanGeneExpressionData(genes_expression)

# EdgeR+voom normalization
genes_expression <- normalizationEdgeR(genes_expression)

# Clean the gene expression dataframe
genes_expression <- cleanGeneExpressionData(genes_expression)

# ordenar os dados por paciente
genes_expression <- orderDataByPatient(genes_expression)
survival_data <- orderDataByPatient(survival_data)

# write on the chunk end time file
log_chunk_end_time("Disease selection and data normalization", log_file = "chunk_times_log.txt")
```

# RSF Ridge Cox Fit and Explore the Models (train != test)

```{r RSF_ridge_cox_Fit_and_Explore_the_Models_different, message=FALSE, warning=FALSE}

# Models' names
models_names_list <- c("Cox", "RandomForest+Cox", "Boruta+Cox") #"SIS", "ISIS", "CausalForest+Cox",

best_alpha <- 0
n_seeds <- 10

# Define the seeds for the iterations
seeds <- seq(1, n_seeds, by = 1)

# Initialize a list to store the coefficients for each iteration
models_coefficients_list <- list()

# Create an empty dataframes to store the evaluation metrics values
c_index_df <- create_metrics_dataframes(seeds, models_names_list)
p_value_df <- create_metrics_dataframes(seeds, models_names_list)
IBS_df <- create_metrics_dataframes(seeds, models_names_list)
num_coeff_df <- create_metrics_dataframes(seeds, models_names_list)

# Memoised function to compute significant variable names
compute_significant_variable_names <- memoise::memoise(
  function(seeds, genes_expression, survival_data) {
    significant_variable_names <- list()
    
    for (i in seeds) {
      logger::log_info("Running univariate cox for seed: {i}")
      
      # Split the data
      splited <- splitTestAndTrain(genes_expression, survival_data, 0.7, i)
      
      genes_expression_train <- splited$expression_train
      survival_train <- splited$survival_train
      genes_expression_test <- splited$expression_test
      survival_test <- splited$survival_test
      
      # Run univariate Cox regression for each variable
      significant_variable_names[[i]] <- univariate_cox(survival_train, genes_expression_train, 0.05) # old 0.05
    }
    
    return(significant_variable_names)
  },
  cache = cd
)

# Call the memoised function
significant_variable_names <- compute_significant_variable_names(seeds, genes_expression, survival_data)

# Loop through the seeds and run the analysis
for (i in seeds) {
  logger::log_info("Running analysis for seed: {i}")
  
  # Split the data
  splited <- splitTestAndTrain(genes_expression, survival_data, 0.7, i)

  genes_expression_train <- splited$expression_train
  survival_train <- splited$survival_train
  genes_expression_test <- splited$expression_test
  survival_test <- splited$survival_test
  
  # reduce the genes expression data frame to only the colunmns of interest
  genes_expression_train <- genes_expression_train[, c("patient", significant_variable_names[[i]])]
  
  # Define survival object
  survival_object_train <- Surv(time = survival_train$days, event = survival_train$vital_status)
  
  # Fit models
  models_coefficients_list[[i]] <- fit_models(genes_expression_train, survival_object_train, best_alpha, survival_train)
  
  # Calculate and store C-index and IBS for each model
  a <- which(seeds == i)
  for (j in seq_along(models_coefficients_list[[i]])) {

    num_coeff_df[j, a] <- length(models_coefficients_list[[i]][[j]]$ensembl_gene_id)
    
    if (num_coeff_df[j, a] > 0) {
      
      c_index_p_value <- calculate_c_index_p_value(survival_object_train, genes_expression_train, models_coefficients_list[[i]][[j]], genes_expression_test, survival_test, survival_data)
      
      c_index_df[j, a] <- c_index_p_value$c_index
      
      p_value_df[j, a] <- c_index_p_value$p_value
      
      IBS_df[j, a] <- calculate_integrated_brier_score(survival_object_train, genes_expression_train, models_coefficients_list[[i]][[j]], genes_expression_test, survival_test)
        
      logger::log_info("seed: ", i)
      logger::log_info("c_index: ", c_index_df[j, a])
      logger::log_info("p_value: ", p_value_df[j, a])
      logger::log_info("IBS: ", IBS_df[j, a])
      
      num_coeff_df[j, a] <- length(models_coefficients_list[[i]][[j]]$ensembl_gene_id)
    } else {

      # If the model has empty coefficients, set C-index and IBS to NA
      c_index_df[j, a] <- NA
      IBS_df[j, a] <- NA
      p_value_df[j, a] <- NA
        }
    }
}

#MRR_C_Index <- calculate_MRR(c_index_df, higher_is_better = TRUE)
#MRR_IBS <- calculate_MRR(IBS_df, higher_is_better = FALSE)

# Initialize empty vectors for Confidence Intervals
c_index_ci_lower <- c()
c_index_ci_upper <- c()
ibs_ci_lower <- c()
ibs_ci_upper <- c()

for (i in seq_len(nrow(c_index_df))) {
  cindex_vals <- as.numeric(c_index_df[i, ])
  ibs_vals <- as.numeric(IBS_df[i, ])
  
  ci_cindex <- compute_confi_inter(cindex_vals) 
  ci_ibs <- compute_confi_inter(ibs_vals) 
  
  c_index_ci_lower[i] <- round(ci_cindex[[1]], 3) 
  c_index_ci_upper[i] <- round(ci_cindex[[2]], 3) 
  
  ibs_ci_lower[i] <- round(ci_ibs[[1]], 3) 
  ibs_ci_upper[i] <- round(ci_ibs[[2]], 3) 
}


# Create a summary table
summary_table <- data.frame(
  C_Index_Avg = round(apply(c_index_df, 1, mean, na.rm = TRUE), 3),
  C_Index_Std_Dev = round(apply(c_index_df, 1, sd, na.rm = TRUE), 3),
  C_Index_95CI = paste0("(", c_index_ci_lower, " – ", c_index_ci_upper, ")"),
  #MRR_C_Index = MRR_C_Index$MRR,
  
  P_value_Avg = round(apply(p_value_df, 1, mean, na.rm = TRUE), 3),
  P_value_Std_Dev = round(apply(p_value_df, 1, sd, na.rm = TRUE), 3),
  
    IBS_Avg = round(apply(IBS_df, 1, mean, na.rm = TRUE), 3),
  IBS_Std_Dev = round(apply(IBS_df, 1, sd, na.rm = TRUE), 3),
  #MRR_IBS = MRR_IBS$MRR,
  IBS_95CI = paste0("(", ibs_ci_lower, " – ", ibs_ci_upper, ")"),
  
  
  
  Coeff_Num_Avg = round(apply(num_coeff_df, 1, mean), 1),
  Coeff_Num_Std_Dev = round(apply(num_coeff_df, 1, sd), 1),
  Non_Convergence_Perc = apply(num_coeff_df, 1, function(x) mean(x == 0) * 100)
)

#Save a summary table as a CSV file
write.csv(summary_table, file = "Results/summary_table.csv", row.names = TRUE)
print(summary_table)

#Save a p-value as a CSV file
write.csv(p_value_df, file = "Results/p_value_df.csv", row.names = TRUE)

#Save a p-value as a CSV file
write.csv(c_index_df, file = "Results/c_index_df.csv", row.names = TRUE)




genes_list_RSF <- list()
for (i in 1:n_seeds) {
  genes_list_RSF[[paste("Seed: ", i)]] <- models_coefficients_list[[i]][[2]]$ensembl_gene_id
}

# write on the chunk end time file
log_chunk_end_time("RSF ridge cox Fit and Explore the Models (train != test)", log_file = "chunk_times_log.txt")
```

# Boruta ElasticNet Cox Fit and Explore the Models (train != test)

```{r Boruta_elasticnet_cox_Fit_and_Explore_the_Models_different, message=FALSE, warning=FALSE}

# Models' names
models_names_list <- c("Cox", "RandomForest+Cox", "Boruta+Cox") #"SIS", "ISIS", "CausalForest+Cox",

best_alpha <- 0.5
n_seeds <- 10

# Define the seeds for the iterations
seeds <- seq(1, n_seeds, by = 1)

# Initialize a list to store the coefficients for each iteration
models_coefficients_list <- list()

# Create an empty dataframes to store the evaluation metrics values
c_index_df <- create_metrics_dataframes(seeds, models_names_list)
p_value_df <- create_metrics_dataframes(seeds, models_names_list)
IBS_df <- create_metrics_dataframes(seeds, models_names_list)
num_coeff_df <- create_metrics_dataframes(seeds, models_names_list)

# Memoised function to compute significant variable names
compute_significant_variable_names <- memoise::memoise(
  function(seeds, genes_expression, survival_data) {
    significant_variable_names <- list()
    
    for (i in seeds) {
      logger::log_info("Running univariate cox for seed: {i}")
      
      # Split the data
      splited <- splitTestAndTrain(genes_expression, survival_data, 0.7, i)
      
      genes_expression_train <- splited$expression_train
      survival_train <- splited$survival_train
      genes_expression_test <- splited$expression_test
      survival_test <- splited$survival_test
      
      # Run univariate Cox regression for each variable
      significant_variable_names[[i]] <- univariate_cox(survival_train, genes_expression_train, 0.05) # old 0.05
    }
    
    return(significant_variable_names)
  },
  cache = cd
)

# Call the memoised function
significant_variable_names <- compute_significant_variable_names(seeds, genes_expression, survival_data)

# Loop through the seeds and run the analysis
for (i in seeds) {
  logger::log_info("Running analysis for seed: {i}")
  
  # Split the data
  splited <- splitTestAndTrain(genes_expression, survival_data, 0.7, i)

  genes_expression_train <- splited$expression_train
  survival_train <- splited$survival_train
  genes_expression_test <- splited$expression_test
  survival_test <- splited$survival_test
  
  # reduce the genes expression data frame to only the colunmns of interest
  genes_expression_train <- genes_expression_train[, c("patient", significant_variable_names[[i]])]
  
  # Define survival object
  survival_object_train <- Surv(time = survival_train$days, event = survival_train$vital_status)
  
  # Fit models
  models_coefficients_list[[i]] <- fit_models(genes_expression_train, survival_object_train, best_alpha, survival_train)
  
  # Calculate and store C-index and IBS for each model
  a <- which(seeds == i)
  for (j in seq_along(models_coefficients_list[[i]])) {

    num_coeff_df[j, a] <- length(models_coefficients_list[[i]][[j]]$ensembl_gene_id)
    
    if (num_coeff_df[j, a] > 0) {
      
      c_index_p_value <- calculate_c_index_p_value(survival_object_train, genes_expression_train, models_coefficients_list[[i]][[j]], genes_expression_test, survival_test, survival_data)
      
      c_index_df[j, a] <- c_index_p_value$c_index
      
      p_value_df[j, a] <- c_index_p_value$p_value
      
      IBS_df[j, a] <- calculate_integrated_brier_score(survival_object_train, genes_expression_train, models_coefficients_list[[i]][[j]], genes_expression_test, survival_test)
        
      logger::log_info("seed: ", i)
      logger::log_info("c_index: ", c_index_df[j, a])
      logger::log_info("p_value: ", p_value_df[j, a])
      logger::log_info("IBS: ", IBS_df[j, a])
      
      num_coeff_df[j, a] <- length(models_coefficients_list[[i]][[j]]$ensembl_gene_id)
    } else {

      # If the model has empty coefficients, set C-index and IBS to NA
      c_index_df[j, a] <- NA
      IBS_df[j, a] <- NA
      p_value_df[j, a] <- NA
        }
    }
}

#MRR_C_Index <- calculate_MRR(c_index_df, higher_is_better = TRUE)
#MRR_IBS <- calculate_MRR(IBS_df, higher_is_better = FALSE)

# Initialize empty vectors for Confidence Intervals
c_index_ci_lower <- c()
c_index_ci_upper <- c()
ibs_ci_lower <- c()
ibs_ci_upper <- c()

for (i in seq_len(nrow(c_index_df))) {
  cindex_vals <- as.numeric(c_index_df[i, ])
  ibs_vals <- as.numeric(IBS_df[i, ])
  
  ci_cindex <- compute_confi_inter(cindex_vals) 
  ci_ibs <- compute_confi_inter(ibs_vals) 
  
  c_index_ci_lower[i] <- round(ci_cindex[[1]], 3) 
  c_index_ci_upper[i] <- round(ci_cindex[[2]], 3) 
  
  ibs_ci_lower[i] <- round(ci_ibs[[1]], 3) 
  ibs_ci_upper[i] <- round(ci_ibs[[2]], 3) 
}


# Create a summary table
summary_table <- data.frame(
  C_Index_Avg = round(apply(c_index_df, 1, mean, na.rm = TRUE), 3),
  C_Index_Std_Dev = round(apply(c_index_df, 1, sd, na.rm = TRUE), 3),
  C_Index_95CI = paste0("(", c_index_ci_lower, " – ", c_index_ci_upper, ")"),
  #MRR_C_Index = MRR_C_Index$MRR,
  
  P_value_Avg = round(apply(p_value_df, 1, mean, na.rm = TRUE), 3),
  P_value_Std_Dev = round(apply(p_value_df, 1, sd, na.rm = TRUE), 3),
  
    IBS_Avg = round(apply(IBS_df, 1, mean, na.rm = TRUE), 3),
  IBS_Std_Dev = round(apply(IBS_df, 1, sd, na.rm = TRUE), 3),
  #MRR_IBS = MRR_IBS$MRR,
  IBS_95CI = paste0("(", ibs_ci_lower, " – ", ibs_ci_upper, ")"),
  
  
  
  Coeff_Num_Avg = round(apply(num_coeff_df, 1, mean), 1),
  Coeff_Num_Std_Dev = round(apply(num_coeff_df, 1, sd), 1),
  Non_Convergence_Perc = apply(num_coeff_df, 1, function(x) mean(x == 0) * 100)
)

#Save a summary table as a CSV file
write.csv(summary_table, file = "Results/summary_table.csv", row.names = TRUE)
print(summary_table)

#Save a p-value as a CSV file
write.csv(p_value_df, file = "Results/p_value_df.csv", row.names = TRUE)

#Save a p-value as a CSV file
write.csv(c_index_df, file = "Results/c_index_df.csv", row.names = TRUE)

genes_list_Boruta <- list()
for (i in 1:n_seeds) {
  genes_list_Boruta[[paste("Seed: ", i)]] <- models_coefficients_list[[i]][[3]]$ensembl_gene_id
}

# write on the chunk end time file
log_chunk_end_time("Boruta Elastic Net Cox Fit and Explore the Models (train != test)", log_file = "chunk_times_log.txt")

```


# Analyse the genes overlapp

```{r Analyse_the_genes_overlapp, message=FALSE, warning=FALSE}

# Important Variables
#genes_list_RSF
#genes_list_Boruta
#significant_variable_names

# Initialize
jaccard_list <- numeric(length(seeds))
fisher_pvals <- numeric(length(seeds))

for (i in seeds) {
  # Extract gene sets
  gene_pool <- significant_variable_names[[i]]                     # Univariate Cox filtered genes
  boruta_genes <- genes_list_Boruta[[paste("Seed: ", i)]]         # Boruta-selected genes
  rsf_genes <- genes_list_RSF[[paste("Seed: ", i)]]                # RSF-selected genes

  # Ensure no NAs
  gene_pool <- na.omit(gene_pool)
  boruta_genes <- na.omit(boruta_genes)
  rsf_genes <- na.omit(rsf_genes)

  # Convert to character (if not already)
  gene_pool <- as.character(gene_pool)
  boruta_genes <- as.character(boruta_genes)
  rsf_genes <- as.character(rsf_genes)

  # Calculate Jaccard index
  intersection <- intersect(boruta_genes, rsf_genes)
  union_genes <- union(boruta_genes, rsf_genes)
  jaccard_index <- length(intersection) / length(union_genes)
  jaccard_list[i] <- jaccard_index

  # Fisher's Exact Test
  A <- length(intersection) # genes que ambos os modelos selecionaram
  B <- length(boruta_genes) - A # genes que só o Boruta quis
  C <- length(rsf_genes) - A # genes que só o RSF quis
  D <- length(setdiff(gene_pool, union_genes)) # genes que nenhum quis

  contingency_matrix <- matrix(c(A, C, B, D), nrow = 2,
                               dimnames = list(Boruta = c("Boruta: Yes", "Boruta: No"),
                                               RSF = c("RSF: Yes", "RSF: No")))
  
  fisher_result <- fisher.test(contingency_matrix)
  fisher_pvals[i] <- fisher_result$p.value
}

# Calculate summary statistics (without rounding)
jaccard_mean <- mean(jaccard_list)
jaccard_sd <- sd(jaccard_list)
fisher_mean <- mean(fisher_pvals)
fisher_sd <- sd(fisher_pvals)

# Print full precision output
cat("\n--- Summary (full precision) ---\n")
cat(paste0("Jaccard Index: ", jaccard_mean, " ± ", jaccard_sd, "\n"))
cat(paste0("Fisher p-value: ", fisher_mean, " ± ", fisher_sd, "\n"))

# Create a dataframe for saving
summary_df <- data.frame(
  Metric = c("Jaccard Index", "Fisher p-value"),
  Mean = c(jaccard_mean, fisher_mean),
  SD = c(jaccard_sd, fisher_sd)
)

# Save to CSV
write.csv(summary_df, file = "Results_Fisher_Jaccard/overlap_statistics.csv", row.names = FALSE)

# write on the chunk end time file
log_chunk_end_time("Analyse the genes overlapp", log_file = "chunk_times_log.txt")
```


